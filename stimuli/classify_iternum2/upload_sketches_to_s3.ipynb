{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "from matplotlib import pyplot,pylab\n",
    "plt = pyplot\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import string\n",
    "import pandas as pd\n",
    "import json\n",
    "import pymongo as pm\n",
    "from glob import glob\n",
    "from IPython.display import clear_output\n",
    "import itertools \n",
    "from random import sample\n",
    "import random\n",
    "import importlib\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up project paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## root paths\n",
    "curr_dir = os.getcwd()\n",
    "proj_dir = os.path.abspath(os.path.join(curr_dir,'../..'))\n",
    "data_dir = os.path.abspath(os.path.join(curr_dir,'../..','data')) ## use relative paths\n",
    "stim_dir = os.path.abspath(os.path.join(proj_dir,'stimuli'))\n",
    "analysis_dir = os.path.abspath(os.path.join(curr_dir,'../..','analysis')) ## use relative paths\n",
    "plot_dir =  os.path.abspath(os.path.join(curr_dir,'../..','results','plots'))\n",
    "csv_dir = os.path.join(proj_dir, 'results','csv')\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'results/sketch'))\n",
    "catch_dir = os.path.abspath(os.path.join(proj_dir,'stimuli/classify_iternum2/catch_trial_stimuli'))    # we want to get the stims for the catch trials in our rating task\n",
    "\n",
    "\n",
    "## add helpers to python path\n",
    "import sys\n",
    "if os.path.join(proj_dir, 'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir, 'utils'))\n",
    "import utils as h    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect stims and get image paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get sketch paths\n",
    "path_to_sketches = sketch_dir\n",
    "im_list = h.list_files(sketch_dir)\n",
    "assert len(im_list)==36*59 # num trials per game * num kosher games\n",
    "\n",
    "## get catch stim paths\n",
    "path_to_catches = catch_dir\n",
    "catch_list = h.list_files(catch_dir)\n",
    "assert len(catch_list)==11\n",
    "\n",
    "catch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sort stims in place\n",
    "importlib.reload(h)\n",
    "h.sort_nicely(im_list)\n",
    "len(im_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## manually inspect the images\n",
    "imwidth = 400\n",
    "imheight = 200\n",
    "fname = im_list[500]\n",
    "print(fname)\n",
    "Image.open(fname).resize((imwidth,imheight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload stims to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import botocore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'iternum2-sketch-stims'\n",
    "full_sketch_paths = h.list_files(path_to_sketches)\n",
    "h.sort_nicely(full_sketch_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper to speed things up by not uploading images if they already exist, can be overriden \n",
    "def check_exists(s3, bucket_name, stim_name):\n",
    "    try:\n",
    "        s3.Object(bucket_name,stim_name).load()    \n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:    \n",
    "        if (e.response['Error']['Code'] == \"404\"):\n",
    "            print('The object does not exist.')\n",
    "            return False\n",
    "        else:\n",
    "            print('Something else has gone wrong with {}'.format(stim_name))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_exists(boto3.resource('s3'), bucket_name, fname.split('/')[-1]))\n",
    "print(fname.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# access the password and username for s3 from our local directory\n",
    "access_id = pd.read_csv(os.path.abspath(os.path.join(curr_dir,'../../../../.aws/credentials')), header = None).values[1][0].split('=')[-1]          \n",
    "access_key = pd.read_csv(os.path.abspath(os.path.join(curr_dir,'../../../../.aws/credentials')), header = None).values[2][0].split('=')[-1]      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reallyRun = 0\n",
    "if reallyRun: \n",
    "    ## tell user some useful information\n",
    "    print('Path to stimuli is : {}'.format(path_to_sketches))\n",
    "    print('Uploading to this bucket: {}'.format(bucket_name))\n",
    "\n",
    "    ## establish connection to s3 \n",
    "#     s3 = boto3.resource('s3')\n",
    "    s3 = boto3.resource('s3', \n",
    "                  region_name='us-east-1', \n",
    "                  aws_access_key_id=access_id, #\"STORE THIS LOCALLY! Boto3 should be accessing ~/.aws/credentials but it's not for some reason\",     \n",
    "                  aws_secret_access_key= access_key ) #'THIS TOO!'\n",
    "    \n",
    "    ## create a bucket with the appropriate bucket name\n",
    "    try: \n",
    "        b = s3.create_bucket(Bucket=bucket_name) \n",
    "        print('Created new bucket.')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        b = s3.Bucket(bucket_name)\n",
    "        print('Bucket already exists.')\n",
    "\n",
    "    ## do we want to overwrite files on s3?\n",
    "    overwrite = False\n",
    "    \n",
    "    ## set bucket and objects to public\n",
    "    b.Acl().put(ACL='public-read') ## sets bucket to public\n",
    "\n",
    "    ## now let's loop through stim paths and actually upload to s3 (woot!)\n",
    "    for i,path_to_file in enumerate(full_sketch_paths):\n",
    "        stim_name = path_to_file.split('/')[-1]\n",
    "        if ((check_exists(s3, bucket_name, stim_name)==False) | (overwrite==True)):\n",
    "            print('Now uploading {} | {} of {}'.format(path_to_file.split('/')[-1],(i+1),len(full_sketch_paths)))\n",
    "            s3.Object(bucket_name,stim_name).put(Body=open(path_to_file,'rb')) ## upload stimuli\n",
    "            s3.Object(bucket_name,stim_name).Acl().put(ACL='public-read') ## set access controls\n",
    "        else: \n",
    "            print('Skipping {} | {} of {} because it already exists.'.format(path_to_file.split('/')[-1],(i+1),len(full_stim_paths)))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print('Done uploading images!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example:\n",
    "# https://iternum2-sketch-stims.s3.amazonaws.com/0326-4c44297a-fe08-4e67-9575-7bfe54c67f58_15bear_trial12.png\n",
    "\n",
    "sketches = [i.split('/')[-1] for i in full_sketch_paths if i.split('/')[-1] != '.DS_Store']\n",
    "\n",
    "to_include = pd.DataFrame(columns = [\"URL\"])\n",
    "\n",
    "for i in range(len(sketches)): # for every sketch\n",
    "    name = sketches[i].split('_') # split up its metadata\n",
    "    \n",
    "                                                             #    gameID    cardinality/animal   trial#\n",
    "    stimurl = \"https://iternum2-sketch-stims.s3.amazonaws.com/\" + name[0] + '_' + name[1] + '_' + name[2]\n",
    "    to_include.loc[len(to_include)] = np.array([stimurl])\n",
    "    \n",
    "len(to_include)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now divide this into 36 paradigms\n",
    "# and upload each paradigm as a big object to the mongo collection\n",
    "# within each paradigm, have a bunch of trials, each of which is a sketch-stim pair\n",
    "\n",
    "random_seed = 619\n",
    "\n",
    "to_include = to_include.sample(frac = 1,random_state=random_seed)  # just totally random sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_urls = ['https://iternum-recog-catches.s3.amazonaws.com/catch1.png',\n",
    "              'https://iternum-recog-catches.s3.amazonaws.com/catch2.png',\n",
    "              'https://iternum-recog-catches.s3.amazonaws.com/catch3.png',\n",
    "              'https://iternum-recog-catches.s3.amazonaws.com/catch4.png',\n",
    "              'https://iternum-recog-catches.s3.amazonaws.com/catch5.png',\n",
    "              'https://iternum-recog-catches.s3.amazonaws.com/catch6.png',\n",
    "              'https://iternum-recog-catches.s3.amazonaws.com/catch7.png',\n",
    "              'https://iternum-recog-catches.s3.amazonaws.com/catch8.png',\n",
    "              'https://iternum-recog-catches.s3.amazonaws.com/catch9.png',\n",
    "              'https://iternum-recog-catches.s3.amazonaws.com/catch10.png',\n",
    "              'https://iternum-recog-catches.s3.amazonaws.com/catch11.png']\n",
    "paradigms = []\n",
    "\n",
    "for p in range(36):\n",
    "    catches = catch_urls\n",
    "    meta = []\n",
    "    thing = to_include[p*59:p*59+59].reset_index().drop('index',axis=1)\n",
    "    counter = 0\n",
    "    \n",
    "    random.seed(p)\n",
    "#     random.shuffle(catches)\n",
    "    \n",
    "    for i,c in enumerate(catches):    # just put all the catches at the beginning, we'll intersperse on index.html\n",
    "        catch = {'cardinality':None,\n",
    "                 'animal':None,\n",
    "                 'origTrialNum':None,\n",
    "                 'URL':catches[i],\n",
    "                 'catch':True}\n",
    "        meta.append(catch)\n",
    "    \n",
    "    for row in thing.iterrows():\n",
    "        counter += 1\n",
    "        url = row[1][0]\n",
    "        obj = url.split('_')[-2]\n",
    "        cardinality,animal = re.split('(\\d+)',obj)[1:3]\n",
    "        origTrial = url.split('_')[-1].split('.')[0]\n",
    "        origTrialNum = re.split('(\\d+)',origTrial)[1]\n",
    "        \n",
    "        trial = {'cardinality':cardinality,\n",
    "                 'animal':animal,\n",
    "                 'origTrialNum':origTrialNum,\n",
    "                 'URL':url,\n",
    "                 'catch':False}\n",
    "        meta.append(trial)\n",
    "                \n",
    "    \n",
    "    paradigm = {'versionID':p,        # which partition is it (set of sketches) ?\n",
    "                'games':[],\n",
    "                'all_games':[], # empty list to be filled with classification games as they happen    \n",
    "                'meta':meta}\n",
    "    paradigms.append(paradigm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org'\n",
    "\n",
    "import pymongo as pm\n",
    "import socket\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1:27017') \n",
    "db = conn['stimuli']\n",
    "coll = db['iternum2_recog2']\n",
    "\n",
    "collist = db.list_collection_names({})\n",
    "\n",
    "if \"iternum2_recog2\" in collist:\n",
    "    print(\"The collection exists.\")\n",
    "else:\n",
    "    db.create_collection('iternum2_recog2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now really insert data\n",
    "reallyRun = False\n",
    "\n",
    "\n",
    "\n",
    "## insert the data\n",
    "if reallyRun:\n",
    "    for (i,j) in enumerate(paradigms):\n",
    "        print('%d of %d uploaded ...' % (i+1,len(paradigms)))\n",
    "        clear_output(wait=True)\n",
    "        coll.insert_one(j)\n",
    "\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload catch stims to a different bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catch_bucket_name = 'iternum-recog-catches'\n",
    "full_catch_paths = h.list_files(path_to_catches)\n",
    "h.sort_nicely(full_catch_paths)\n",
    "\n",
    "full_catch_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reallyRun = 1\n",
    "if reallyRun: \n",
    "    ## tell user some useful information\n",
    "    print('Path to stimuli is : {}'.format(path_to_catches))\n",
    "    print('Uploading to this bucket: {}'.format(catch_bucket_name))\n",
    "\n",
    "    ## establish connection to s3 \n",
    "#     s3 = boto3.resource('s3')\n",
    "    s3 = boto3.resource('s3', \n",
    "                  region_name='us-east-1', \n",
    "                  aws_access_key_id=access_id, #\"STORE THIS LOCALLY! Boto3 should be accessing ~/.aws/credentials but it's not for some reason\",     \n",
    "                  aws_secret_access_key= access_key ) #'THIS TOO!'\n",
    "    \n",
    "    ## create a bucket with the appropriate bucket name\n",
    "    try: \n",
    "        b = s3.create_bucket(Bucket=catch_bucket_name) \n",
    "        print('Created new bucket.')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        b = s3.Bucket(catch_bucket_name)\n",
    "        print('Bucket already exists.')\n",
    "\n",
    "    ## do we want to overwrite files on s3?\n",
    "    overwrite = False\n",
    "    \n",
    "    ## set bucket and objects to public\n",
    "    b.Acl().put(ACL='public-read') ## sets bucket to public\n",
    "\n",
    "    ## now let's loop through stim paths and actually upload to s3 (woot!)\n",
    "    for i,path_to_file in enumerate(full_catch_paths):\n",
    "        stim_name = path_to_file.split('/')[-1]\n",
    "        if ((check_exists(s3, catch_bucket_name, stim_name)==False) | (overwrite==True)):\n",
    "            print('Now uploading {} | {} of {}'.format(path_to_file.split('/')[-1],(i+1),len(full_catch_paths)))\n",
    "            s3.Object(catch_bucket_name,stim_name).put(Body=open(path_to_file,'rb')) ## upload stimuli\n",
    "            s3.Object(catch_bucket_name,stim_name).Acl().put(ACL='public-read') ## set access controls\n",
    "        else: \n",
    "            print('Skipping {} | {} of {} because it already exists.'.format(path_to_file.split('/')[-1],(i+1),len(full_catch_paths)))\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print('Done uploading images!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
