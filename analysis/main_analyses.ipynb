{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "\n",
    "# Main Analyses\n",
    "\n",
    "## Contents:\n",
    "* [Import Packages + Set up Paths](#import)\n",
    "\n",
    "\n",
    "* [Connect to Mongo](#mongo)  \n",
    "\n",
    "\n",
    "* [Save Dataframes from Each Experiment](#initialize)  \n",
    "    * [Experiment 1.0](#exp1_data): sketcher data (T), viewer data (K), dyad data (D)\n",
    "    * [Experiment 1.1](#exp1_rdat): recognizer data (R)\n",
    "    * [Experiment 2.0](#exp2_data): sketcher data (T), viewer data (K), dyad data (D)\n",
    "    * [Experiment 3.0](#exp3_data): sender data (S), receiver data (C), dyad data (D)  \n",
    "\n",
    "\n",
    "* [Read Dataframes Back Up](#read_from_csv)\n",
    "    * Can start here to read from locally stored data and save time\n",
    "\n",
    "\n",
    "* [Summary Statistics](#summary_stats)\n",
    "    * [Summary of the Data](#summary): Also includes some simple exploratory statistical tests\n",
    "    * [Idealized Strategies](#strategies): How close are participants' messages to strategies we imagine a priori?   \n",
    "    * [Orderedness](#orderedness): How often are symbols within messages in decreasing order of size?\n",
    "\n",
    "\n",
    "* [Figures in Manuscript](#figures)\n",
    "    * [Figure 2B & 2C](#fig2)\n",
    "    * [Figure 3B & 3C](#fig3)\n",
    "    * [Figure 4B & 4C](#fig4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"import\"></a> Import Packages + Set up Paths ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import math\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from IPython.display import SVG, display # need for showing stims with sketches side by side\n",
    "import requests # this is to access the stim urls from the notebook\n",
    "import base64\n",
    "import PIL\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "from matplotlib import rcParams\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "from IPython.display import clear_output\n",
    "import importlib\n",
    "from collections import Counter # for counting games\n",
    "\n",
    "# directory & file hierarchy\n",
    "proj_dir =     os.path.abspath('..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir =  os.path.join(proj_dir,'results')\n",
    "plot_dir =     os.path.join(results_dir,'plots')\n",
    "csv_dir =      os.path.join(results_dir,'csv')\n",
    "extra_dir =      os.path.join(csv_dir,'extra')\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'utils'))\n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [results_dir,plot_dir,csv_dir,extra_dir]]\n",
    "\n",
    "## add utils to python path\n",
    "if os.path.join(proj_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'utils'))\n",
    "import utils\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Functions & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set preferences for how we run this notebook (some operations are time-consuming)\n",
    "save_images = True             # automatically save sketches + galleries for Experiments 1 & 2\n",
    "extra_exclusions = False        # exclude a few games in Experiment 3 or not?\n",
    "\n",
    "# set general preferences for figure aesthetics\n",
    "lw = 3\n",
    "cs = 3\n",
    "\n",
    "# What is our colour palette? Others are #97b4c2 (simpsons err fill), #25B1F7 (exp1 stroke ratio line), #25B1F7 (exp2 bar fill)\n",
    "c1 = '#7DCCF4'\n",
    "c2 = '#787878' # '#0c54c7'\n",
    "c3 = '#97b4c2'\n",
    "\n",
    "np.random.seed(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sketch(df,exp,ID,Gid,trialNum,sketch_dir=False):\n",
    "    \"\"\"\n",
    "    Just a function that plots a sketch (specified by the gameID and trial number) with its target stimulus.\n",
    "    Output of this function is the image showing both side by side.\n",
    "    \"\"\"\n",
    "    game = df[df.gameID == ID]\n",
    "    trial = game[game.trialNum == trialNum]\n",
    "    stim_url = trial['Targ_s_Url'].values[0]\n",
    "    get_stim = requests.get(stim_url)\n",
    "    stim = Image.open(BytesIO(get_stim.content))\n",
    "    correct = trial['outcome'].values[0]\n",
    "    background_colour = \"#1EB012\" if correct == 1 else \"#D31F13\"\n",
    "    get_sketch = trial['png'].values[0]\n",
    "    sketch = Image.open(BytesIO(base64.b64decode(get_sketch)))\n",
    "    \n",
    "    sketch = sketch.resize((100,100))\n",
    "    stim = stim.resize((100,100))\n",
    "    \n",
    "    images = [sketch,stim]\n",
    "    widths, heights = zip(*(i.size for i in images))\n",
    "    total_width = max(widths)\n",
    "    max_height = sum(heights)\n",
    "    whole_trial = Image.new('RGBA', (total_width, max_height),color=background_colour)\n",
    "    y_offset = 0\n",
    "    \n",
    "    for im in images:\n",
    "        whole_trial.paste(im, (0,y_offset))\n",
    "        y_offset += im.size[1] + 5\n",
    "    \n",
    "    if sketch_dir != False:\n",
    "        condition = df[df.gameID == ID]['Game_Condition'].values[0]\n",
    "        fname = str(condition) + '_G' + str(Gid) + \"_trial\" + str(trialNum) + '_' + str(trial['target'].values[0])\n",
    "        if not os.path.exists(os.path.join(sketch_dir,fname+'.png')):\n",
    "            print('Rendering sketch...', fname + '.png')\n",
    "            clear_output(wait=True)\n",
    "            whole_trial.save(os.path.join(sketch_dir,fname+'.png'),'PNG')\n",
    "    \n",
    "    return whole_trial\n",
    "\n",
    "def get_gallery(df,exp,ID,Gid,save_dir=False,by_trial=False):\n",
    "    \"\"\"\n",
    "    This function takes in a gameID and shows sketches and their targets for every trial, side by side.\n",
    "    Optionally, it will save this output into a png.\n",
    "    exp is the experiment, 1 or 2. ID is gameID, Gid is a shorter integer id\n",
    "    \"\"\"\n",
    "    d = df[df.gameID == ID]\n",
    "    width = 32 if exp==1 else 36\n",
    "    numTrials = int(d['trialNum'].max())\n",
    "    sketch_dir = save_dir.replace(\"sketch_galleries\",\"sketch\")\n",
    "    \n",
    "    if by_trial == False:\n",
    "        whole_game = Image.new('RGBA', (int(width*100/2), 410),color='white')\n",
    "        whole_game.putalpha(0)\n",
    "        cardinalities = np.sort(d['cardinality'].unique())\n",
    "        animals = d['category'].unique()\n",
    "        for i,c in enumerate(cardinalities):\n",
    "            for j,a in enumerate(animals):\n",
    "                # get all the instances of this cardinality-animal combo in the game (there are 2!)\n",
    "                trialnums = d.loc[(d.cardinality == c) & (d.category == a)]['trialNum'].unique()\n",
    "                for k,t in enumerate(trialnums):\n",
    "                    \n",
    "                    trial = get_sketch(df,exp,ID,Gid,int(t),sketch_dir=sketch_dir)\n",
    "                    \n",
    "                    whole_game.paste(trial,(j*100+i*300,k*205)) # k is binary - so either 0 or 205\n",
    "    \n",
    "    if by_trial == True:\n",
    "        whole_game = Image.new('RGBA', (width*100, 205),color='white')\n",
    "        whole_game.putalpha(0)\n",
    "        for trial_num in np.arange(1,numTrials+1):\n",
    "            trial = get_sketch(df,exp,ID,Gid,trial_num,sketch_dir=sketch_dir)\n",
    "            whole_game.paste(trial,(trial_num*100-100,0))\n",
    "\n",
    "            \n",
    "    if save_dir != False:\n",
    "        split_by = 'Game_Condition' if exp == 1 else 'Regularity'\n",
    "        condition = df[df.gameID == ID][split_by].values[0]\n",
    "        fname = str(condition) + '_G' + str(Gid) + \"_gallery\"\n",
    "                    \n",
    "        # now save the image out to that directory\n",
    "        if not os.path.exists(os.path.join(save_dir,fname+'.png')):\n",
    "            print('Rendering gallery...', fname + '.png')\n",
    "            clear_output(wait=True)\n",
    "            whole_game.save(os.path.join(save_dir,fname+'.png'),'PNG')\n",
    "            \n",
    "    return whole_game\n",
    "\n",
    "def get_confint(df):\n",
    "    \"\"\"Takes a df already with columns ['Factors','mean','count','std'] \"\"\"\n",
    "    new_df = df\n",
    "    ci95_hi = []\n",
    "    ci95_lo = []\n",
    "    for i in new_df.index:\n",
    "        m, c, s = new_df.loc[i]\n",
    "        ci95_hi.append(m + 1.96*s/math.sqrt(c))\n",
    "        ci95_lo.append(m - 1.96*s/math.sqrt(c))\n",
    "    new_df['ci95_hi'] = ci95_hi\n",
    "    new_df['ci95_lo'] = ci95_lo\n",
    "    return new_df\n",
    "\n",
    "def LD(token1, token2):\n",
    "    \"\"\"This function gives us the Levenshtein distance between two strings.\n",
    "    We will use it to cluster games into categories based on which model strategies they are closest to\"\"\"\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]\n",
    "\n",
    "# check to see if the symbols are being used in a strictly decreasing order\n",
    "def ordered(x,dis=False):\n",
    "    \"\"\" Checks to see if a list is consistent with being (decreasingly) ordered \"\"\"\n",
    "    ordered = True # assume that the list is decreasingly ordered by default\n",
    "    \n",
    "    if dis == True & len(x) == 1: # if we are looking for places where it *could* be disordered but isn't\n",
    "        ordered = np.nan # if there's only one symbol, it's meaningless whether it's ordered\n",
    "    \n",
    "    else: # most cases are this\n",
    "        curItem = x[0] # start with first element of the list\n",
    "        for i,item in enumerate(x):\n",
    "            ordered = False if item > curItem else True # check to see if next element is greater than previous\n",
    "            curItem = item\n",
    "            if ordered == False:  # if any subsequent list item increases, then stop searching\n",
    "                break\n",
    "    return ordered\n",
    "\n",
    "# as a control, posit a fake set of symbols that sums to the same number:\n",
    "def getFakeMessage(x):\n",
    "    \"\"\"m for message, r for remainder\"\"\"\n",
    "    r = x\n",
    "    m = []\n",
    "    while r > 0:\n",
    "        new_symbol = np.random.choice(np.arange(1,r+1),1)\n",
    "        m = np.append(m, new_symbol)\n",
    "        r -= new_symbol\n",
    "    return m.astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"mongo\"></a> Connect to Mongo ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ssh -fNL 27020:127.0.0.1:27017 sholt@cogtoolslab.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv(os.path.join(analysis_dir,'auth.txt'), header = None) # this auth.txt file contains the password\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org'\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "import socket\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1:27017')\n",
    "db = conn['iterated_number']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"initialize\"></a> Save Dataframes from Each Experiment ([^](#top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"exp1_data\"></a> Experiment 1 - Communication Task ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare to pick out Experiment 1 communication data from mongo\n",
    "coll = db['num8_shape4']\n",
    "iterationNames = ['run2','run3','run4','run5','run6']\n",
    "\n",
    "## fetch viewer records that match our list of iterationNames, then turn that into a dataframe for raw data\n",
    "print(\"Fetching viewer data...\")\n",
    "clear_output(wait=True)\n",
    "k = coll.find({'iterationName': {'$in': iterationNames}, 'eventType':'clickedObj'})\n",
    "K = pd.DataFrame(list(k))\n",
    "\n",
    "## now do the same for stroke data\n",
    "print(\"Fetching sketcher data...\")\n",
    "clear_output(wait=True)\n",
    "t = coll.find({'iterationName': {'$in': iterationNames}, 'eventType':'stroke'})\n",
    "T = pd.DataFrame(list(t))\n",
    "\n",
    "## get list of valid game IDs (i.e, subject number)\n",
    "game_dict = Counter(K['gameid']) ## get dictionary mapping gameIDs to number of sketches \n",
    "complete_gameids = [k for (k,v) in game_dict.items() if v==32] ## get gameids that contributed exactly the right number of sketches\n",
    "\n",
    "## take only stroke/sketch dataframes that are complete, and only bother if there are incomplete games\n",
    "only_complete = True\n",
    "if (only_complete and T['gameid'].nunique()!=len(complete_gameids)):\n",
    "    T = T[(T['gameid'].isin(complete_gameids))].reset_index(drop=True)\n",
    "    K = K[(K['gameid'].isin(complete_gameids))].reset_index(drop=True)\n",
    "\n",
    "# save out to csv\n",
    "T.drop(columns=['workerId']).to_csv(os.path.join(csv_dir,'extra/exp1_stroke_raw.csv'),index=False) # anonymize\n",
    "K.drop(columns=['workerId']).to_csv(os.path.join(csv_dir,'extra/exp1_sketch_raw.csv'),index=False) # anonymize\n",
    "\n",
    "print(\"There are {} complete games.\".format(len(complete_gameids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment these to generate D again\n",
    "D = utils.generate_dataframe(coll, complete_gameids, \"1\", csv_dir)\n",
    "\n",
    "# Turning things that can be numeric into numeric things\n",
    "D = D.astype({'trialNum': 'float',\n",
    "              'cardinality': 'float',\n",
    "              'drawDuration': 'float',\n",
    "              'outcome': 'float',\n",
    "              'numStrokes': 'float',\n",
    "              'meanPixelIntensity': 'float',\n",
    "              'numCurvesPerSketch': 'float',\n",
    "              'numCurvesPerStroke': 'float',\n",
    "              'D1_Car': 'float',\n",
    "              'D2_Car': 'float',\n",
    "              'D3_Car': 'float'})\n",
    "\n",
    "# Keep track of which quarter of the experiment the trial happened in\n",
    "D['block'] = np.ceil(D['trialNum'] / 8)          # group trials into blocks\n",
    "D['cardinality'] = D['cardinality'] + 1          # cardinalities are 0-indexed, which is ugly\n",
    "D['ratio'] = D['numStrokes'] / D['cardinality']  # stroke ratio\n",
    "D = D.astype({'block': 'float'})                 # need this as numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# are we looking at all complete games, or only ones that pass the criteria for analysis?\n",
    "exclude = True\n",
    "\n",
    "# Export the csv a first time with all the data - including everyone we'll have to exclude\n",
    "D.to_csv(os.path.join(csv_dir,'extra/exp1_dyad_raw.csv'))\n",
    "\n",
    "\n",
    "# First clean it up by removing games that we have to exclude. Some exclusions require looking first:\n",
    "dud_games = [\"8369-76e6f73d-922a-4aca-b98a-8c96026aa48a\",    #number; excluded because of below-threshold accuracy\n",
    "             \"1372-60cdfd55-28bb-411c-b777-c51eaadee7a9\",    #shape; below-threshold accuracy\n",
    "             \"2949-1e579088-8493-4c07-873c-7bd6d00685e3\",    #shape; included pre-existing symbols\n",
    "             \"7197-6d1f3fda-040a-455c-aef0-279ba9aef053\",    #shape; included pre-existing symbols\n",
    "             \"9237-4cc76e85-9955-4cef-b03c-5c68f46321ca\",    #shape; below-threshold accuracy\n",
    "             \"1947-29382ba4-5747-456d-ba8b-276812fc1fb3\"]    #shape; below-threshold accuracy\n",
    "\n",
    "# there are also automatically detectable criteria for exclusion\n",
    "low_acc_games = D[D['low_acc'] == True]['gameID'].unique()    # unusually low accuracy\n",
    "failed_games =  D[D['failed'] == True]['gameID'].unique()    # below 50% accuracy\n",
    "\n",
    "# the names of the games we want to keep\n",
    "games_list = [game for game in complete_gameids if game not in dud_games] if exclude == True else complete_gameids\n",
    "\n",
    "# now exclude games that didn't meet analysis criteria\n",
    "D = D[(D['gameID'].isin(games_list))].reset_index(drop=True)\n",
    "\n",
    "# Export the csv again. This is what the R script will look at\n",
    "D.to_csv(os.path.join(csv_dir,'exp1_dyad.csv'))\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now save qualitative data to file, if we have enabled it\n",
    "if save_images == True:\n",
    "    for i,game_id in enumerate(D['gameID'].unique()):\n",
    "        print(\"Now generating sketch + stim display for \",game_id)\n",
    "        clear_output(wait=True)\n",
    "        get_gallery(D,1,game_id,i,save_dir='../results/sketch_galleries/exp1',by_trial=True)\n",
    "\n",
    "        \n",
    "# # if we want to also generate sketches readable to VGG-19, uncomment the rest of this\n",
    "# k1 = pd.read_csv(os.path.join(csv_dir,'extra/exp1_sketch_raw.csv'))\n",
    "# k1 = k1.loc[k1['gameid'].isin(D1['gameID'].unique())]\n",
    "\n",
    "# importlib.reload(utils)\n",
    "# utils.render_images(k1,data = 'pngString',\n",
    "#                     metadata = ['gameid','intendedName','trialNum','game_condition'],\n",
    "#                     targ_url = ['targ_s_url'],\n",
    "#                     out_dir = \"../results/bare_sketches\",\n",
    "#                     targ_dir = \"../results/bare_targets\",\n",
    "#                     delimiter = '_',\n",
    "#                     savetargs = True)\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"exp1_rdat\"></a> Experiment 1 - Recognition Task ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare to pick out Experiment 1 recognition data from mongo\n",
    "coll = db['num8_shape4_recognition']\n",
    "iterationName = 'run1'\n",
    "\n",
    "## fetch records that match our list of iterationNames\n",
    "print(\"Fetching recognition task data...\")\n",
    "clear_output(wait=True)\n",
    "r = coll.find({'iterationName': iterationName})\n",
    "R = pd.DataFrame(list(r))\n",
    "\n",
    "## get list of valid game IDs (i.e, subject number)\n",
    "game_dict = Counter(R['recog_gameID']) ## get dictionary mapping gameIDs to number of trials \n",
    "complete_gameids = [r for (r,v) in game_dict.items() if v==65]    # 65 trials is a full game in this one\n",
    "\n",
    "## subset stroke/sketch dataframes by being complete\n",
    "only_complete = True\n",
    "if (only_complete and R['recog_gameID'].nunique()!=len(complete_gameids)):\n",
    "    R = R[(R['recog_gameID'].isin(complete_gameids))].reset_index(drop=True)\n",
    "\n",
    "# rename columns for shorter reference\n",
    "R = R.rename(columns={\"recog_gameID\":\"RgameID\",\n",
    "                      \"orig_game_id\":\"OgameID\", \n",
    "                      \"rating_trial_num\":\"Rtrial\",\n",
    "                      \"orig_game_trial_num\":\"Otrial\",\n",
    "                      \"rate_condition\":\"Rcond\",\n",
    "                      \"orig_game_condition\":\"Ocond\",\n",
    "                      \"orig_sketch_animal\":\"shape\",\n",
    "                      \"orig_sketch_cardinality\":\"cardinality\"\n",
    "                     })\n",
    "\n",
    "# Turning things that can always be numeric into numeric things\n",
    "R = R.astype({'cardinality': 'float',\n",
    "              'Rtrial': 'float',\n",
    "              'Otrial': 'float'})\n",
    "\n",
    "# For accuracy, we have to compare a different set of columns, depending each rating condition\n",
    "R['correct'] = R.apply(lambda x: float(x['rating']) == x['cardinality'] if x['Rcond'] == 'number' else x['rating'] == x['shape'],axis=1)\n",
    "\n",
    "R = R.astype({'correct': 'float'})      \n",
    "\n",
    "# need to add trial block of original game here, as well\n",
    "R['block'] = np.ceil(R['Otrial'] / 8)\n",
    "\n",
    "# convert milliseconds to seconds\n",
    "R['RT'] = R['RT'] / 1000\n",
    "\n",
    "# finally, what we're really interested in is whether recognizers are in the same or different condition as communicators\n",
    "R['sameCond'] = R['Ocond'] == R['Rcond']\n",
    "\n",
    "# save out to csv\n",
    "R.drop(columns=['workerID']).to_csv(os.path.join(csv_dir,'extra/exp1_recog_raw.csv'),index=False) # anonymize\n",
    "\n",
    "print(\"There are {} complete recognition games.\".format(len(complete_gameids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many distinct recog participants completed all trials of the game, prior to exclusion criteria?\n",
    "num_complete_raters = len(R.workerID.unique())\n",
    "\n",
    "# make a dataframe showing each recognizer's catch trial accuracy\n",
    "catches = R[R['catch_trial'] == True]\n",
    "catch_acc = pd.DataFrame(catches.groupby(['RgameID','workerID'])['correct'].mean())\n",
    "catch_acc = catch_acc.rename(columns={\"correct\": \"catch_accuracy\"})\n",
    "num_games = len(catch_acc)\n",
    "\n",
    "# now get a list of the gameIDs who got perfect score on catch trials and filter everyone else out of the big DF\n",
    "kosher_games = list(catch_acc[catch_acc['catch_accuracy'] == 1.0].reset_index()['RgameID'])\n",
    "is_kosher = R.RgameID.isin(kosher_games) # get the indices of games that pass. Boolean series\n",
    "R = R[is_kosher] # now filter R to include only those games that passed\n",
    "R = R[R['catch_trial'] == False] # now remove all catch trials from R, as we don't need to analyse them\n",
    "num_kosher_games = len(kosher_games)\n",
    "\n",
    "print(\"{} recog games passed all catch trials, out of {} total.\".format(num_kosher_games,num_games))\n",
    "print(\"{} total unique workers passed this stage\".format(len(R.workerID.unique())))\n",
    "\n",
    "# get all the workers who participated in the production task\n",
    "workerList = np.append(K['workerId'].unique(),T['workerId'].unique())\n",
    "is_repeat = R.workerID.isin(workerList)\n",
    "R = R[~is_repeat]\n",
    "num_naive = len(R.workerID.unique())\n",
    "num_games_naive = len(R.RgameID.unique())\n",
    "\n",
    "print(\"{} recog participants completed all trials.\".format(num_complete_raters))\n",
    "print(\"{} recog participants not repeated from production.\".format(num_naive))\n",
    "print(\"{} recog games not from repeaters, out of {} total.\".format(num_games_naive,num_kosher_games))\n",
    "print(\"{} total unique workers passed this stage\".format(len(R.workerID.unique())))\n",
    "\n",
    "# now save out the whole dataframe so we can run analyses in R:\n",
    "R.drop(columns=['workerID']).to_csv(os.path.join(csv_dir,\"exp1_recog.csv\")) # anonymize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"exp2_data\"></a> Experiment 2 ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prepare to pick out Experiment 2 communication data from mongo\n",
    "coll = db['num6_shape3']\n",
    "iterationNames = ['regularity1','run1']\n",
    "\n",
    "## fetch viewer records that match our list of iterationNames, then turn that into a dataframe for raw data\n",
    "print(\"Fetching viewer data...\")\n",
    "clear_output(wait=True)\n",
    "k = coll.find({'iterationName': {'$in': iterationNames}, 'eventType':'clickedObj'})\n",
    "K = pd.DataFrame(list(k))\n",
    "\n",
    "## now do the same for stroke data\n",
    "print(\"Fetching sketcher data...\")\n",
    "clear_output(wait=True)\n",
    "t = coll.find({'iterationName': {'$in': iterationNames}, 'eventType':'stroke'})\n",
    "T = pd.DataFrame(list(t))\n",
    "\n",
    "# make a new column for viewer reaction time\n",
    "K['vRT'] = K['clickedTime'] - K['submitTime'] # viewer reaction time\n",
    "\n",
    "# convert to seconds so that it's easier to read\n",
    "K['vRT'] = K['vRT'] / 1000\n",
    "\n",
    "## get list of valid game IDs (i.e, subject number)\n",
    "game_dict = Counter(K['gameid']) ## get dictionary mapping gameIDs to number of sketches \n",
    "complete_gameids = [k for (k,v) in game_dict.items() if v==36] ## get gameids that contributed exactly the right number of sketches\n",
    "\n",
    "## take only stroke/sketch dataframes that are complete, and only bother if there are incomplete games\n",
    "only_complete = True\n",
    "if (only_complete and T['gameid'].nunique()!=len(complete_gameids)):\n",
    "    T = T[(T['gameid'].isin(complete_gameids))].reset_index(drop=True)\n",
    "    K = K[(K['gameid'].isin(complete_gameids))].reset_index(drop=True)\n",
    "\n",
    "# save out to csv\n",
    "T.drop(columns=['workerId']).to_csv(os.path.join(csv_dir,'extra/exp2_stroke_raw.csv'),index=False) # anonymize\n",
    "K.drop(columns=['workerId']).to_csv(os.path.join(csv_dir,'extra/exp2_sketch_raw.csv'),index=False) # anonymize\n",
    "\n",
    "print(\"There are {} complete games.\".format(len(complete_gameids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment these to generate D again\n",
    "D = utils.generate_dataframe(coll, complete_gameids, \"2\", csv_dir)\n",
    "\n",
    "# Turning things that can be numeric into numeric things\n",
    "D = D.astype({'trialNum': 'float',\n",
    "              'cardinality': 'float',\n",
    "              'drawDuration': 'float',\n",
    "              'outcome': 'float',\n",
    "              'numStrokes': 'float',\n",
    "              'meanPixelIntensity': 'float',\n",
    "              'numCurvesPerSketch': 'float',\n",
    "              'numCurvesPerStroke': 'float',\n",
    "              'D1_Car': 'float',\n",
    "              'D2_Car': 'float',\n",
    "              'D3_Car': 'float'})\n",
    "\n",
    "# Keep track of which block of the experiment the trial happened in\n",
    "D['block'] = np.ceil(D['trialNum'] / 6)          # group trials into blocks\n",
    "D['cardinality'] = D['cardinality'] + 1          # cardinalities are 0-indexed, which is ugly\n",
    "D = D.astype({'block': 'float'})                 # need this as numeric\n",
    "\n",
    "# generate a column in D showing the relationship between cardinality and numstrokes (use of 1-to-1)\n",
    "D['putative_1to1'] = D['numStrokes'] == D['cardinality']\n",
    "D['strategy'] = D['putative_1to1'].replace(False, 'other').replace(True, '1-to-1') \n",
    "D['ratio'] = D['numStrokes'] / D['cardinality']  # stroke ratio\n",
    "\n",
    "# now let's add in to D the vRT column from the clicked-object dataframe\n",
    "toAdd = K[['gameid','trialNum','vRT']].rename(columns={\"gameid\": \"gameID\"})\n",
    "D = D.merge(toAdd, on=['gameID','trialNum'])\n",
    "\n",
    "# Export the csv a first time with all the data - including everyone we'll have to exclude\n",
    "D.to_csv(os.path.join(csv_dir,'extra/exp2_dyad_raw.csv'))\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First clean it up by removing games that we have to exclude. Get dud games manually:\n",
    "dud_games = ['9852-69340911-592c-4469-91a1-7bb58ae4fc40',    # wrote Arabic numbers\n",
    "             '1532-126aa9fb-b331-4b1d-b3bd-14b8d397fe69',    # wrote Arabic numbers\n",
    "             '8455-59b6d31b-21c8-4534-aa89-7d96be21275c',    # wrote Arabic numbers\n",
    "             '0379-88447599-199d-4930-86eb-45a5bcfcd0e9',    # wrote Arabic numbers\n",
    "             '5057-8314d547-2119-484b-8ed8-292ba0819395',    # wrote Arabic numbers\n",
    "             '6814-d2c17a13-a0f0-459c-b10e-a11fb6b6046d']    # wrote Arabic numbers\n",
    "\n",
    "# Make exclusions. There are also automatically detectable criteria for exclusion\n",
    "D = D.loc[(~D['gameID'].isin(dud_games)) & (D['low_acc'] == False) & (D['failed'] == False)]\n",
    "\n",
    "# Some vRT outliers - a few were negative, and a few astronomical (throwing off standard deviation), ~70 in total. Make them np.nan\n",
    "D.loc[(D['vRT'] < 0) | (D['vRT'] > D['vRT'].std()*4),'vRT'] = np.nan\n",
    "\n",
    "# And also render it in seconds rather than milliseconds\n",
    "D['vRT'] = D['vRT'] / 1000\n",
    "\n",
    "# Export the csv again. This is what the R script will look at\n",
    "D.to_csv(os.path.join(csv_dir,'exp2_dyad.csv'))\n",
    "\n",
    "# One additional set of possible exclusions, which had to do with measurement error\n",
    "dud_games = ['2534-036a9276-5839-475f-a859-75e96c529c74',    # weird sketcher RT glitch. One of these is already excluded due to low accuracy\n",
    "             '2590-5c03c7de-2316-42ef-917e-75dcf4ea3d70',    # weird sketcher RT glitch\n",
    "             '7919-3b01f5d5-343e-4dd4-a3f3-da5504807930',    # weird sketcher RT glitch\n",
    "             '9229-771b97f0-185b-4ecc-86a0-dec48211501c']    # weird sketcher RT glitch\n",
    "\n",
    "# Make exclusions. There are also automatically detectable criteria for exclusion\n",
    "D_ex = D.loc[(~D['gameID'].isin(dud_games))]\n",
    "\n",
    "# Export the csv again. This is what the R script will look at\n",
    "D_ex.to_csv(os.path.join(csv_dir,'exp2_dyad_excl.csv'))\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now save qualitative data to file, if we have enabled it\n",
    "if save_images == True:\n",
    "    for i,game_id in enumerate(D['gameID'].unique()):\n",
    "        print(\"Now generating sketch + stim display for \",game_id)\n",
    "        clear_output(wait=True)\n",
    "        get_gallery(D,2,game_id,i,save_dir='../results/sketch_galleries/exp2')\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"exp3_data\"></a> Experiment 3 ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3\n",
    "coll = db['dots1']\n",
    "iterationNames = ['run1']\n",
    "\n",
    "# get the dataframe of symbols that were made\n",
    "print(\"Fetching sender data...\")\n",
    "clear_output(wait=True)\n",
    "s = coll.find({'iterationName':iterationName,'eventType':'newSymbols'})\n",
    "S = pd.DataFrame(s)\n",
    "\n",
    "# get the dataframe of clicked objects and distractors\n",
    "print(\"Fetching receiver data...\")\n",
    "clear_output(wait=True)\n",
    "c = coll.find({'iterationName':iterationName,'eventType':'clickedObj'})\n",
    "C = pd.DataFrame(c)\n",
    "\n",
    "# get the dataframe (not working yet) of post-survey resposes (ideally, two per game), now saved with the rest of our data\n",
    "print(\"Fetching post-test survey data...\")\n",
    "clear_output(wait=True)\n",
    "p = coll.find({'iterationName':iterationName,'eventType':'posttestSurvey'})\n",
    "P = pd.DataFrame(p)\n",
    "\n",
    "## Clean the Dataframes\n",
    "print(\"Now cleaning data...\")\n",
    "clear_output(wait=True)\n",
    "\n",
    "# didn't store cardinality independently of stimulus / clicked name... not a big deal, just extract it\n",
    "S[['dot','cardinality']] = S.intendedName.str.split(\"_\",expand=True)\n",
    "C[['dot','cardinality']] = C.intendedName.str.split(\"_\",expand=True)\n",
    "C[['clickedDot','clicked']] = C.clickedName.str.split(\"_\",expand=True) # only one has clicked name\n",
    "\n",
    "# cast things to the type we want them to be\n",
    "S = S.astype({'cardinality':'int'})\n",
    "C = C.astype({'cardinality':'int',\n",
    "              'previous_score':'int',\n",
    "              'clicked':'int'})\n",
    "\n",
    "# zero-indexing is confusing, let's make some measures a little more intuitive\n",
    "S['cardinality'] = S['cardinality'] + 1\n",
    "C['cardinality'] = C['cardinality'] + 1\n",
    "C['clicked'] = C['clicked'] + 1\n",
    "\n",
    "# seconds are easier to figure out than milliseconds. Get the duration of different trial components\n",
    "C['totalTrialDuration'] = (C['confirmTime'] - C['trialStartTime']) / 1000\n",
    "C['RT'] = (C['confirmTime'] - C['submitTime']) / 1000      # how long the receiver took ('response time')\n",
    "C['PT'] = (C['submitTime'] - C['trialStartTime']) / 1000   # how long the sender took ('production time')\n",
    "\n",
    "# clean the post-test survey datastructure, taking only what matters, and expanding the surveyData column\n",
    "P = P[['gameid','prolificID','previous_score','surveyData','comments']]\n",
    "P[['understood']] = P[['surveyData']].applymap(lambda x: x[2])\n",
    "P[['gender']] = P[['surveyData']].applymap(lambda x: x[3])\n",
    "P[['age']] = P[['surveyData']].applymap(lambda x: int(x[4]))\n",
    "P[['likePartner']] = P[['surveyData']].applymap(lambda x: x[5])\n",
    "P[['role']] = P[['surveyData']].applymap(lambda x: x[6])\n",
    "P[['totalTime']] = P[['surveyData']].applymap(lambda x: x[7])\n",
    "P[['OS']] = P[['surveyData']].applymap(lambda x: x[8])\n",
    "P = P.drop(columns=['surveyData'])                                 # don't need the un-parsed column anymore\n",
    "\n",
    "# now merge the Senders' and Receivers' dataframes, on both game and trial number (unique)\n",
    "D = S.merge(C, on=['gameid','trialNum'])\n",
    "\n",
    "# get the cardinality of each of the two distractors on each trial\n",
    "D['d1'] = D['dis_s_urls_x'].apply(lambda x: x[0].split('_')[-2])\n",
    "D['d2'] = D['dis_s_urls_x'].apply(lambda x: x[1].split('_')[-2])\n",
    "D = D.astype({'d1':'int',\n",
    "              'd2':'int'})\n",
    "\n",
    "# rename columns as needed (using camelCaps)\n",
    "D = D.rename(columns={\"gameid\":\"gameID\",\n",
    "                      \"prolificID_x\":\"senderID\", # Prolific things\n",
    "                      \"prolificID_y\":\"receiverID\",\n",
    "                      \"iterationName_x\":\"iterationName\", # when in doubt, keep only Sender's version\n",
    "                      \"trialStartTime_x\":\"trialStartTime\",\n",
    "                      \"intendedName_x\":\"intendedName\",\n",
    "                      \"submitTime_x\":\"submitTime\",\n",
    "                      \"targ_s_url_x\":\"targetURL\",\"dis_s_urls_x\":\"disURLs\",\n",
    "                      \"cardinality_x\":\"cardinality\",\n",
    "                      \"previous_score\":\"score\",\n",
    "                      \"object3SketcherLoc\":\"targetLoc\"\n",
    "                     })\n",
    "\n",
    "# clear out unnecessary columns\n",
    "D = D.drop(columns=['_id_x', '_id_y','time_x',\n",
    "                    'workerId_x', 'workerId_y',  # AMT stuff - now using Prolific\n",
    "                    'assignmentId_x','assignmentId_y',  # AMT stuff - now using Prolific\n",
    "                    'iterationName_y','trialStartTime_y','time_y',\n",
    "                    'viewer_sees_images_x','viewer_sees_images_y',\n",
    "                    'regularity_x','regularity_y',\n",
    "                    'intendedName_y','submitTime_y','studyID_y',\n",
    "                    'game_condition_x','game_condition_y',\n",
    "                    'eventType_x','eventType_y','dot_x','dot_y','cardinality_y','dis_v_urls_x',\n",
    "                    'object1Name','object2Name','object3Name',\n",
    "                    'object1SketcherLoc', 'object1ViewerLoc', \n",
    "                    'object2SketcherLoc', 'object2ViewerLoc',\n",
    "                    'object3ViewerLoc',                        #       'object3SketcherLoc' is now the target location, but viewerLoc irrelevant\n",
    "                    'condition', 'phase', 'repetition','previous_bonus_score',\n",
    "                    'targ_s_url_y', 'targ_v_url_y', 'dis_s_urls_y','dis_v_urls_y','targ_v_url_x',\n",
    "                    'clickedName','clickedDot',\n",
    "                    'studyID_x','sessionID_x','sessionID_y'])\n",
    "\n",
    "# The participant's message is currently a list, read as a string. Turn it back into a list of integers\n",
    "D['symbols'] = D[['symbols']].applymap(lambda x: list(map(int, x.split(',')))) # currently a string, make it a list\n",
    "\n",
    "# reorder the columns so it's nice :)\n",
    "D = D[['iterationName',         # ID: what iteration is it? Things change between iterations\n",
    "       'senderID',              # ID: Sender's Prolific ID\n",
    "       'receiverID',            # ID: Receiver's Prolific ID\n",
    "       'gameID',                # ID: every game (dyad) has a unique identifier\n",
    "       'trialNum',              # ID: what trial were they on? every game-trial pair is unique and exhaustive\n",
    "       'trialStartTime',        # TIME: when did the trial start?\n",
    "       'submitTime',            # TIME: when did Sender click 'submit'?\n",
    "       'clickedTime',           # TIME: when did Receiver click their selection?\n",
    "       'confirmTime',           # TIME: when did Receiver confirm their selection?\n",
    "       'totalTrialDuration',    # TIME: how long did the whole trial take (trialStart to confirm)?\n",
    "       'PT',                    # TIME: how long did Sender take (trialStart to submit)?\n",
    "       'RT',                    # TIME: how long did Receiver take (submit to confirm)?\n",
    "       'cardinality',           # ACC: what CARDINALITY was the target?\n",
    "       'clicked',               # ACC: what CARDINALITY did Receiver select?\n",
    "       'correct',               # ACC: was the choice correct?\n",
    "       'score',                 # ACC: whatever their score was; important for bonusing\n",
    "       'symbols',               # SIGNAL: what did Sender send?\n",
    "       'symbolsProcess',        # SIGNAL: what else did they select along the way, and when?\n",
    "       'targetLoc',             # STIM: where the target was for the Sender\n",
    "       'd1',                    # STIM: what is distractor cardinality #1?\n",
    "       'd2'                     # STIM: what is distractor cardinality #2?\n",
    "       ]]\n",
    "\n",
    "# get the ratio between token count (i.e. message length) and set size\n",
    "D[['messageLength']] = D[['symbols']].applymap(lambda x: len(x))\n",
    "D['tokenRatio'] = D['messageLength'] / D['cardinality']\n",
    "\n",
    "# Export the csv a first time with all the data - including everyone we'll have to exclude\n",
    "D.drop(columns=['senderID', 'receiverID']).to_csv(os.path.join(csv_dir,'extra/exp3_dyad_raw.csv')) # anonymize\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Excluding Games\n",
    "total_N = D.gameID.nunique() # how many games did we recruit in total?\n",
    "\n",
    "# find games that didn't have enough trials or were mostly wrong\n",
    "completeGames = dict(D.groupby(['gameID'])['trialNum'].max() == 32) # dict mapping full games to number of trials\n",
    "correctGames = dict(D.groupby(['gameID'])['correct'].mean() > .5) # dict mapping correct-ish games to their percent correct\n",
    "\n",
    "# now delete those games from the dataframe, also recording how many games remain after each exclusion\n",
    "D = D[D['gameID'].apply(lambda x: completeGames[x] == True)]\n",
    "complete_N = D.gameID.nunique() # how many games were complete?\n",
    "D = D[D['gameID'].apply(lambda x: correctGames[x] == True)]\n",
    "correct_N = D.gameID.nunique() # how many games were complete?\n",
    "\n",
    "# and keep only valid games in the post-test survey dataframe\n",
    "good_games = D.gameID.unique()\n",
    "P = P[P['gameid'].apply(lambda x: x in good_games)]\n",
    "\n",
    "# Export the csv again. This is what the R script will look at\n",
    "D.drop(columns=['senderID', 'receiverID']).to_csv(os.path.join(csv_dir,'exp3_dyad.csv')) # anonymize\n",
    "\n",
    "print(\"There were {} games begun, {} who finished the task, and {} who passed enough trials.\".format(total_N,\n",
    "                                                                                                     complete_N,\n",
    "                                                                                                     correct_N))\n",
    "print(\"{} female, M_age = {}, SD_age = {}\".format(P['gender'].value_counts()['female'],\n",
    "                                                  np.round(P['age'].mean(),2), np.round(P['age'].std(),2)))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"read_from_csv\"></a> Read Dataframes Back Up ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D1 = pd.read_csv(os.path.join(csv_dir,'exp1_dyad.csv'))\n",
    "D2 = pd.read_csv(os.path.join(csv_dir,'exp1_recog.csv'))\n",
    "D3 = pd.read_csv(os.path.join(csv_dir,'exp2_dyad.csv'))\n",
    "D3e = pd.read_csv(os.path.join(csv_dir,'exp2_dyad_excl.csv'))\n",
    "D4 = pd.read_csv(os.path.join(csv_dir,'exp3_dyad.csv'))\n",
    "\n",
    "# reading up from a csv turned the 'symbols' column of D4 back into a string... so, flip it back\n",
    "D4['symbolslist'] = D4[['symbols']].applymap(lambda x: list(map(int, x.replace(']','').replace('[','').split(',')))) # currently a string, make it a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"summary_stats\"></a> Summary Statistics ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"How many games do we have in each experiment / condition?\")\n",
    "print(\"Exp 1.0  Number : {}\".format(D1.loc[D1['Game_Condition']=='number']['gameID'].nunique()))\n",
    "print(\"         Shape  : {}\".format(D1.loc[D1['Game_Condition']=='shape']['gameID'].nunique()),end='\\n\\n')\n",
    "print(\"Exp 1.1  Number : {}\".format(D2.loc[D2['Rcond']=='number']['RgameID'].nunique()))\n",
    "print(\"         Shape  : {}\".format(D2.loc[D2['Rcond']=='shape']['RgameID'].nunique()),end='\\n\\n')\n",
    "print(\"Exp 2    Random : {}\".format(D3.loc[D3['Regularity']=='random']['gameID'].nunique()))\n",
    "print(\"         Regular: {}\".format(D3.loc[D3['Regularity']=='regular']['gameID'].nunique()),end='\\n\\n')\n",
    "print(\"Exp 3    All    : {}\".format(D4['gameID'].nunique()   ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"summary\"></a> Summary of the Data ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# how many sig figs do we want when displaying rounded numbers? Write a function for displaying them\n",
    "def r(x,sigfigs=2):\n",
    "    \"\"\" Rounds number to the nearest sigfig for printing (and prints trailing 0s) \"\"\"\n",
    "    newnum = \"{:.\"+ str(sigfigs) +\"f}\"\n",
    "    return newnum.format(x)\n",
    "\n",
    "D1acc = get_confint(pd.DataFrame(D1.groupby(['Game_Condition'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "print(\"Experiment 1A - Accuracy\")\n",
    "print(\"    Number: {}%, CI: [{},{}]\".format(r(D1acc.loc['number','mean']*100), r(D1acc.loc['number','ci95_lo']*100), r(D1acc.loc['number','ci95_hi']*100)))\n",
    "print(\"    Shape : {}%, CI: [{},{}]\".format(r(D1acc.loc['shape','mean']*100),  r(D1acc.loc['shape','ci95_lo']*100),  r(D1acc.loc['shape','ci95_hi']*100)))\n",
    "print(\"\")\n",
    "\n",
    "D1['one2one'] = D1['ratio'] == 1\n",
    "D1one = get_confint(pd.DataFrame(D1.groupby(['Game_Condition'])['one2one'].agg(['mean', 'count', 'std'])))\n",
    "print(\"Experiment 1A - Frequency of 1-to-1 Strategy\")\n",
    "print(\"    Number: {}%, CI: [{},{}]\".format(r(D1one.loc['number','mean']*100), r(D1one.loc['number','ci95_lo']*100), r(D1one.loc['number','ci95_hi']*100)))\n",
    "print(\"    Shape : {}%, CI: [{},{}]\".format(r(D1one.loc['shape','mean']*100),  r(D1one.loc['shape','ci95_lo']*100),  r(D1one.loc['shape','ci95_hi']*100)))\n",
    "print(\"\")\n",
    "\n",
    "D1['compressed'] = D1['ratio'] < 1\n",
    "D1cpr = get_confint(pd.DataFrame(D1.groupby(['Game_Condition'])['compressed'].agg(['mean', 'count', 'std'])))\n",
    "print(\"Experiment 1A - Frequency of Compressed Strategy\")\n",
    "print(\"    Number: {}%, CI: [{},{}]\".format(r(D1cpr.loc['number','mean']*100), r(D1cpr.loc['number','ci95_lo']*100), r(D1cpr.loc['number','ci95_hi']*100)))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "D2opp = D2.loc[D2['Ocond'] != D2['Rcond']]\n",
    "D2acc = get_confint(pd.DataFrame(D2opp.groupby(['Ocond'])['correct'].agg(['mean', 'count', 'std'])))\n",
    "print(\"Experiment 1B - Recovering Irrelevant Information\")\n",
    "print(\"    Number: {}%, CI: [{},{}]\".format(r(D2acc.loc['number','mean']*100), r(D2acc.loc['number','ci95_lo']*100), r(D2acc.loc['number','ci95_hi']*100)))\n",
    "print(\"    Shape : {}%, CI: [{},{}]\".format(r(D2acc.loc['shape','mean']*100),  r(D2acc.loc['shape','ci95_lo']*100),  r(D2acc.loc['shape','ci95_hi']*100)))\n",
    "print(\"\")\n",
    "\n",
    "extra_exclusions = False\n",
    "d3 = D3e if extra_exclusions == True else D3 # we also want to look at the games with the response time measurement error\n",
    "\n",
    "D3acc = get_confint(pd.DataFrame(d3.groupby(['Regularity'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "print(\"Experiment 2 - Accuracy\")\n",
    "print(\"    Random : {}%, CI: [{},{}]\".format(r(D3acc.loc['random','mean']*100), r(D3acc.loc['random','ci95_lo']*100), r(D3acc.loc['random','ci95_hi']*100)))\n",
    "print(\"    Regular: {}%, CI: [{},{}]\".format(r(D3acc.loc['regular','mean']*100),r(D3acc.loc['regular','ci95_lo']*100),r(D3acc.loc['regular','ci95_hi']*100)))\n",
    "print(\"\")\n",
    "\n",
    "d3['one2one'] = d3['ratio'] == 1\n",
    "D3one = get_confint(pd.DataFrame(d3.groupby(['Regularity'])['one2one'].agg(['mean', 'count', 'std'])))\n",
    "print(\"Experiment 2 - Frequency of 1-to-1 Strategy\")\n",
    "print(\"    All    : {}%\".format(r(d3['one2one'].mean()*100)))\n",
    "print(\"    Random : {}%, CI: [{},{}]\".format(r(D3one.loc['random','mean']*100), r(D3one.loc['random','ci95_lo']*100), r(D3one.loc['random','ci95_hi']*100)))\n",
    "print(\"    Regular: {}%, CI: [{},{}]\".format(r(D3one.loc['regular','mean']*100),r(D3one.loc['regular','ci95_lo']*100),r(D3one.loc['regular','ci95_hi']*100)))\n",
    "print(\"\")\n",
    "\n",
    "d3['compressed'] = d3['ratio'] < 1\n",
    "D3cpr = get_confint(pd.DataFrame(d3.groupby(['Regularity'])['compressed'].agg(['mean', 'count', 'std'])))\n",
    "print(\"Experiment 2 - Frequency of Compressed Strategy\")\n",
    "print(\"    All    : {}%\".format(r(d3['compressed'].mean()*100)))\n",
    "print(\"    Random : {}%, CI: [{},{}]\".format(r(D3cpr.loc['random','mean']*100), r(D3cpr.loc['random','ci95_lo']*100), r(D3cpr.loc['random','ci95_hi']*100)))\n",
    "print(\"    Regular: {}%, CI: [{},{}]\".format(r(D3cpr.loc['regular','mean']*100),r(D3cpr.loc['regular','ci95_lo']*100),r(D3cpr.loc['regular','ci95_hi']*100)))\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "D4['one2one'] = D4['tokenRatio'] == 1\n",
    "D4['compressed'] = D4['tokenRatio'] < 1\n",
    "print(\"Experiment 3\")\n",
    "print(\"    Accuracy    : {}%\".format(r(D4['correct'].mean()*100)))\n",
    "print(\"    1-1         : {}%\".format(r(D4['one2one'].mean()*100)))\n",
    "print(\"    1-1 (no 1s) : {}%\".format(r(D4.loc[D4['cardinality']!=1]['one2one'].mean()*100)))\n",
    "\n",
    "d4one2one = D4.loc[D4['cardinality']!=1]['one2one']    # make this a bit shorter of an expression\n",
    "pval = stats.fisher_exact([[d3['one2one'].sum(), d3['one2one'].count() - d3['one2one'].sum()],\n",
    "                    [d4one2one.sum(), d4one2one.count() - d4one2one.sum()]])[1]\n",
    "print(\"            Fisher w/ Ex2 p = {}\".format(r(pval,sigfigs=4)))\n",
    "print(\"    Compressed  : {}%\".format(r(D4['compressed'].mean()*100)))\n",
    "\n",
    "print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"strategies\"></a> Idealized Strategies ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, create idealized versions of main strategies\n",
    "string  = True\n",
    "Baseof4 = {}\n",
    "One2one = {}\n",
    "Ordinal = {}\n",
    "Calqued = {}  # calquing the Arabic numerals. There's no zero, so the closest thing would be:\n",
    "#  1,  2,  3,  4\n",
    "# 11, 12, 13, 14\n",
    "# 21, 22, 23, 24\n",
    "# 31, 32, 33, 34\n",
    "\n",
    "for number in range(1,17):\n",
    "    remainder = [number % 4] if number % 4 != 0 else []\n",
    "    Baseof4[number] = \"\".join([str(token) for token in (number // 4)*[4] + remainder]) if string == True else (number // 4)*[4] + remainder   \n",
    "    One2one[number] = \"\".join([str(token) for token in number * [1]]) if string == True else number * [1]\n",
    "    Calqued[number] = str((number-1)//4 if (number-1)//4!=0 else '') + str(number%4 if number%4!=0 else 4)\n",
    "    \n",
    "# now compare actual data to these strategies. How similar is current token to a perfect strategy using...\n",
    "D4['dist2baseof4'] = D4.apply(lambda x: LD(\"\".join([str(token) for token in x['symbolslist']]), Baseof4[x['cardinality']]), axis=1)    # ... base-4?\n",
    "D4['dist2one2one'] = D4.apply(lambda x: LD(\"\".join([str(token) for token in x['symbolslist']]), One2one[x['cardinality']]), axis=1)    # ... 1-to-1?\n",
    "D4['dist2calqued'] = D4.apply(lambda x: LD(\"\".join([str(token) for token in x['symbolslist']]), Calqued[x['cardinality']]), axis=1)    # ... ciphered-positional?\n",
    "D4['dist2ordinal'] = D4.apply(lambda x: LD(\"\".join([str(token) for token in x['symbolslist']]), str(x['targetLoc']))      , axis=1)    # ... ordinal cue?\n",
    "\n",
    "# and, keep the reference model on hand for each\n",
    "D4['baseof4'] = D4.apply(lambda x: list(Baseof4[x['cardinality']]), axis=1)\n",
    "D4['one2one'] = D4.apply(lambda x: list(One2one[x['cardinality']]), axis=1)\n",
    "D4['calqued'] = D4.apply(lambda x: list(Calqued[x['cardinality']]), axis=1)\n",
    "# reference model for ordinal is already on hand, as 'targetLoc'\n",
    "\n",
    "# Now we can spit out a classification for each game\n",
    "print(\"What strategies do we classify each game as having used?\")\n",
    "strategy_counts = D4.groupby(['gameID'])[['dist2baseof4','dist2one2one','dist2calqued','dist2ordinal']].mean().apply(lambda x: np.argmin(x),axis=1).value_counts()\n",
    "print(\"    Base-4 : {} games\".format(strategy_counts[0]))\n",
    "print(\"    1-to-1 : {} games\".format(strategy_counts[1]))\n",
    "print(\"    Calqued: {} games\".format(strategy_counts[2]))\n",
    "print(\"    Ordinal: {} games\".format(strategy_counts[3]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"orderedness\"></a> Orderedness ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now look into the monotonic ordering of symbols within messages\n",
    "D4['fake'] = D4['symbolslist'].apply(lambda x: getFakeMessage(np.sum(x)))   # we will generate some 'random chance' messages, which still add up to the correct number\n",
    "D4['ordered'] = D4[['symbolslist']].applymap(lambda x: int(ordered(x)))\n",
    "D4['disordered'] = D4[['symbolslist']].applymap(lambda x: float(ordered(x,dis=True)))\n",
    "D4['fake_ordered'] = D4[['fake']].applymap(lambda x: float(ordered(x)))\n",
    "D4['fake_disordered'] = D4[['fake']].applymap(lambda x: float(ordered(x,dis=True)))\n",
    "\n",
    "print(\"How many messages were decreasingly ordered?\")\n",
    "print(\"All      : {}\".format(r(D4['ordered'].mean()*100)))\n",
    "print(\"Correct  : {}\".format(r(D4.groupby(['correct'])['ordered'].mean()[True]*100)))\n",
    "print(\"Incorred : {}\".format(r(D4.groupby(['correct'])['ordered'].mean()[False]*100)),end='\\n\\n')\n",
    "\n",
    "ttest_order = stats.ttest_ind(D4['ordered'], D4['fake_ordered'],\n",
    "                              permutations=1000, equal_var=False, random_state=20)\n",
    "\n",
    "print(\"Were messages significantly more ordered than expected by chance?\")\n",
    "print(\"t = {},  p = {}\".format(r(ttest_order[0],sigfigs=3),r(ttest_order[1],sigfigs=3)),end='\\n\\n')\n",
    "\n",
    "ttest_RT = stats.ttest_ind(np.array(D4[D4['ordered']==0]['RT']), np.array(D4[D4['ordered']==1]['RT']),\n",
    "                           equal_var=False, random_state=20)\n",
    "ttest_PT = stats.ttest_ind(np.array(D4[D4['ordered']==0]['PT']), np.array(D4[D4['ordered']==1]['PT']),\n",
    "                           equal_var=False, random_state=20)\n",
    "\n",
    "print(\"Were ordered messages faster to produce or interpret?\")\n",
    "print(\"Interpreting:    t = {},  p = {}\".format(r(ttest_RT[0],sigfigs=3),r(ttest_RT[1],sigfigs=3)))\n",
    "print(\"Producing   :    t = {},  p = {}\".format(r(ttest_PT[0],sigfigs=3),r(ttest_PT[1],sigfigs=3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a name=\"figures\"></a> Figures in Manuscript ([^](#top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"fig2\"></a> Figures 2B & 2C ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 2B\n",
    "\n",
    "acc_DF = get_confint(pd.DataFrame(D1.groupby(['Game_Condition'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "condition_acc = get_confint(pd.DataFrame(D2.groupby(['Rcond','Ocond'])['correct'].agg(['mean', 'count', 'std']))).reset_index()        \n",
    "\n",
    "fig , (ax1,ax2,ax3,ax0,ax4) = plt.subplots(1,5 , figsize = (12,4),\n",
    "                                       gridspec_kw={'width_ratios': [2,2,2,.8,10]})\n",
    "\n",
    "ax1.set_ylim(0,1)\n",
    "ax2.set_ylim(0,1)\n",
    "ax3.set_ylim(0,1)\n",
    "\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_yticks([0,.5,1])\n",
    "ax1.set_yticklabels(['0','.5','1'])\n",
    "ax2.set_yticks([])\n",
    "ax3.set_yticks([])\n",
    "ax2.set_yticklabels([])\n",
    "ax3.set_yticklabels([])\n",
    "\n",
    "\n",
    "ax0.set_yticks([])\n",
    "ax0.set_yticklabels([])\n",
    "ax0.set_xticks([])\n",
    "ax0.set_xticklabels([])\n",
    "ax0.axis('off')\n",
    "\n",
    "\n",
    "ax1.bar(acc_DF.reset_index()['Game_Condition'],\n",
    "        height=acc_DF['mean'],\n",
    "        color = [c1,c2], alpha=1,\n",
    "        yerr= acc_DF['ci95_hi']-acc_DF['mean'],\n",
    "        error_kw={'linewidth':lw,'capsize':cs,'markeredgewidth':lw})\n",
    "\n",
    "\n",
    "\n",
    "number_acc = condition_acc[condition_acc['Rcond'] == 'number']\n",
    "ax2.bar(number_acc['Ocond'],\n",
    "        height=number_acc['mean'],\n",
    "        color = [c1,c2], alpha=1,\n",
    "        yerr= number_acc['ci95_hi']-number_acc['mean'],\n",
    "        error_kw={'linewidth':lw,'capsize':cs,'markeredgewidth':lw})\n",
    "\n",
    "\n",
    "\n",
    "shape_acc = condition_acc[condition_acc['Rcond'] == 'shape']\n",
    "ax3.bar(shape_acc['Ocond'],\n",
    "        height=shape_acc['mean'],\n",
    "        color = [c1,c2], alpha=1,\n",
    "        yerr= shape_acc['ci95_hi']-shape_acc['mean'],\n",
    "        error_kw={'linewidth':lw,'capsize':cs,'markeredgewidth':lw})\n",
    "\n",
    "ax1.set_xticks([])\n",
    "ax1.set_xticklabels([])\n",
    "ax2.set_xticks([])\n",
    "ax2.set_xticklabels([])\n",
    "ax3.set_xticks([])\n",
    "ax3.set_xticklabels([])\n",
    "ax2.set_xlabel(\"Number\")\n",
    "ax3.set_xlabel(\"Shape\")\n",
    "\n",
    "ax1.set_xlabel(\"Viewers\")\n",
    "ax1.xaxis.set_label_coords(.5, -.15)\n",
    "\n",
    "\n",
    "l1=ax1.axhline(0.25,color='black',ls='--')\n",
    "l1.set_label('l1')\n",
    "\n",
    "l2=ax2.axhline(0.125,color='black',ls='--')\n",
    "l2.set_label('l2')\n",
    "\n",
    "l3=ax3.axhline(0.25,color='black',ls='--')\n",
    "l3.set_label('l3')\n",
    "\n",
    "\n",
    "# Figure 2C\n",
    "# Process the data to plot. First, we'll separate the conditions\n",
    "df_num = D1.loc[D1['Game_Condition'] == 'number']\n",
    "df_aml = D1.loc[D1['Game_Condition'] == 'shape']\n",
    "\n",
    "# then calculate confidence intervals for estimated stroke count within each cardinality\n",
    "num_str_trial_DF = get_confint(pd.DataFrame(df_num.groupby(['cardinality'])['numStrokes'].agg(['mean', 'count', 'std'])))\n",
    "aml_str_trial_DF = get_confint(pd.DataFrame(df_aml.groupby(['cardinality'])['numStrokes'].agg(['mean', 'count', 'std'])))\n",
    "\n",
    "# we'll plot each condition onto the axis separately\n",
    "ax4.errorbar(np.arange(1,len(aml_str_trial_DF)+1)+.05, aml_str_trial_DF['mean'],\n",
    "             yerr = aml_str_trial_DF['ci95_hi'] - aml_str_trial_DF['mean'],\n",
    "             linewidth=lw, capsize=cs, elinewidth=lw, markeredgewidth=lw, c=c2)\n",
    "ax4.errorbar(np.arange(1,len(num_str_trial_DF)+1)-.05, num_str_trial_DF['mean'],\n",
    "             yerr = num_str_trial_DF['ci95_hi'] - num_str_trial_DF['mean'],\n",
    "             linewidth=lw, capsize=cs, elinewidth=lw, markeredgewidth=lw, c=c1)\n",
    "\n",
    "# add labels, etc\n",
    "ax4.legend(('Shape Games','Number Games'),loc=\"upper left\")\n",
    "ax4.yaxis.tick_right()\n",
    "ax4.set_xlabel(\"Cardinality\")\n",
    "ax4.set_ylabel(\"Stroke Count\",rotation=270)\n",
    "ax4.set_ylim(0,np.ceil(np.max(num_str_trial_DF['ci95_hi']))) # set y-limit to be the nearest integer above max err val\n",
    "ax4.yaxis.set_label_position(\"right\")\n",
    "ax4.yaxis.set_label_coords(1.1, .5)\n",
    "\n",
    "\n",
    "plt.tight_layout(w_pad=.3)\n",
    "\n",
    "ax5 = fig.add_subplot(111, frameon=False)\n",
    "# hide tick and tick label of the big axis\n",
    "ax5.set_position(pos=[.1,.25,.37,.1])\n",
    "ax5.tick_params(labelcolor='none', which='both', top=False, bottom=False, left=False, right=False)\n",
    "ax5.set_xlabel(\"Recognizers\")\n",
    "ax5.set_ylabel(\"\")\n",
    "\n",
    "\n",
    "fig.savefig('../results/plots/Fig_2BC.pdf')\n",
    "# fig.savefig('../results/plots/Fig_2BC.png')\n",
    "# fig.savefig('../results/plots/Fig_2BC.svg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"fig3\"></a> Figures 3B & 3C ([^](#top))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_DF = get_confint(pd.DataFrame(D3.groupby(['Regularity'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "subject_acc = pd.DataFrame(D3.groupby(['Regularity','gameID'])['outcome'].mean()).reset_index()\n",
    "\n",
    "fig , (ax1,ax2)= plt.subplots(1,2,figsize=(5,4),gridspec_kw={'width_ratios': [2, 2]})\n",
    "\n",
    "barw = .35\n",
    "\n",
    "ax1.bar([.3,.7],\n",
    "        height=acc_DF['mean'],\n",
    "        width=barw,\n",
    "        yerr=[acc_DF['ci95_hi']-acc_DF['mean'], acc_DF['mean']-acc_DF['ci95_lo']],\n",
    "        error_kw=dict(lw=lw, capsize=cs, capthick=lw))\n",
    "ax1.set_ylim([0,1])\n",
    "ax2.set_xlabel(\"\")\n",
    "\n",
    "ax1.get_children()[1].set_color(c1) # was hollow, as (0,0,0,0)\n",
    "ax1.get_children()[2].set_color(c2) # was hollow, as (0,0,0,0)\n",
    "ax1.get_children()[1].set_edgecolor(c1)\n",
    "ax1.get_children()[2].set_edgecolor(c2)\n",
    "\n",
    "\n",
    "ran_acc_trial_DF = get_confint(pd.DataFrame(D3[D3['Regularity']=='random'].groupby(['trialNum'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "reg_acc_trial_DF = get_confint(pd.DataFrame(D3[D3['Regularity']=='regular'].groupby(['trialNum'])['outcome'].agg(['mean', 'count', 'std'])))\n",
    "\n",
    "# show points as subject accuracies:\n",
    "ran_subject_acc = np.array(subject_acc[subject_acc['Regularity']=='random']['outcome'])\n",
    "reg_subject_acc = np.array(subject_acc[subject_acc['Regularity']=='regular']['outcome'])\n",
    "\n",
    "\n",
    "\n",
    "time_DF = get_confint(pd.DataFrame(D3.groupby(['Regularity'])['drawDuration'].agg(['mean', 'count', 'std'])))\n",
    "subject_time = pd.DataFrame(D3.groupby(['Regularity','gameID'])['drawDuration'].mean()).reset_index()\n",
    "\n",
    "ax2.bar([.3,.7],\n",
    "        height=time_DF['mean'],\n",
    "        width=barw,\n",
    "        yerr=[time_DF['ci95_hi']-time_DF['mean'], time_DF['mean']-time_DF['ci95_lo']],\n",
    "        error_kw=dict(lw=lw, capsize=cs, capthick=lw))\n",
    "ax2.set_xlabel(\"\")\n",
    "\n",
    "ax2.get_children()[1].set_color(c1) # was hollow, as (0,0,0,0)\n",
    "ax2.get_children()[2].set_color(c2) # was hollow, as (0,0,0,0)\n",
    "ax2.get_children()[1].set_edgecolor(c1)\n",
    "ax2.get_children()[2].set_edgecolor(c2)\n",
    "\n",
    "# show points as subject draw times:\n",
    "ran_subject_time = np.array(subject_time[subject_time['Regularity']=='random']['drawDuration'])\n",
    "reg_subject_time = np.array(subject_time[subject_time['Regularity']=='regular']['drawDuration'])\n",
    "\n",
    "ax1.set_xticklabels([])\n",
    "ax2.set_xticklabels([])\n",
    "\n",
    "ax1.set_yticks([0,1])\n",
    "ax1.set_yticklabels(['0','1'])\n",
    "ax2.set_yticks([0,5,10,15])\n",
    "ax2.set_yticklabels(['0s','','','15s'])\n",
    "\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax2.set_ylabel(\"Draw Time\",rotation=270)\n",
    "ax1.yaxis.set_label_coords(-.05, .5)\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.yaxis.set_label_position(\"right\")\n",
    "ax2.yaxis.set_label_coords(1.3, .5)\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout(w_pad=.3)\n",
    "\n",
    "fig.savefig('../results/plots/Fig_3BC.pdf')\n",
    "# fig.savefig('../results/plots/Fig_3BC.png')\n",
    "# fig.savefig('../results/plots/Fig_3BC.svg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a name=\"fig4\"></a> Figures 4B & 4C ([^](#top))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. a function we're going to use\n",
    "def getCI95(x,g=False):\n",
    "    upper = np.mean(x) + 1.96*np.std(x)/math.sqrt((len(x)))\n",
    "    lower = np.mean(x) - 1.96*np.std(x)/math.sqrt((len(x)))\n",
    "    if g == True:\n",
    "        upper = stats.gmean(x) + 1.96*stats.gstd(x)/math.sqrt((len(x)))\n",
    "        lower = stats.gmean(x) - 1.96*stats.gstd(x)/math.sqrt((len(x)))\n",
    "\n",
    "    return upper - lower\n",
    "\n",
    "# 2. some extra columns we're going to use\n",
    "D4[['1norm']] = D4[['symbolslist']].applymap(lambda x: x.count(1)/len(x))\n",
    "D4[['2norm']] = D4[['symbolslist']].applymap(lambda x: x.count(2)/len(x))\n",
    "D4[['3norm']] = D4[['symbolslist']].applymap(lambda x: x.count(3)/len(x))\n",
    "D4[['4norm']] = D4[['symbolslist']].applymap(lambda x: x.count(4)/len(x))\n",
    "\n",
    "# 3. let's look at the diversity in representations of each cardinality\n",
    "classification = 'cardinality'\n",
    "\n",
    "# 4. get the estimate for Simpson's diversity index\n",
    "simpsons = D4.groupby([classification,'symbols'])[['symbols']].count(\n",
    ").groupby(classification)[['symbols']].apply(\n",
    "    lambda x: 1 - (sum([y*(y-1) for y in list(x['symbols'])]) / \n",
    "    (x['symbols'].sum()*(x['symbols'].sum() - 1))))\n",
    "\n",
    "simpsons.name = 'Simpson'\n",
    "\n",
    "# 5. now bootstrap some uncertainty around that measure\n",
    "subset_sims = np.zeros([len(D[classification].unique()),0])\n",
    "\n",
    "for i in range(100):\n",
    "    np.random.seed(i)\n",
    "    subset_games = np.random.choice(D4.gameID.unique(), len(D4.gameID.unique()), replace=True)\n",
    "    subset_D4 = D4[D4['gameID'].apply(lambda x: x in subset_games)]\n",
    "    cur_sim = np.array(subset_D4.groupby([classification,'symbols'])[['symbols']].count(\n",
    "    ).groupby(classification)[['symbols']].apply(\n",
    "        lambda x: 1 - (sum([y*(y-1) for y in list(x['symbols'])]) / \n",
    "                       (x['symbols'].sum()*(x['symbols'].sum() - 1)))))\n",
    "    \n",
    "    subset_sims = np.append(subset_sims,np.array([cur_sim]).T,axis=1)\n",
    "    \n",
    "upperCI = np.quantile(subset_sims, .975, axis=1, keepdims = True, interpolation = 'nearest') # can't use 'method' because my python is outdated\n",
    "lowerCI = np.quantile(subset_sims, .025, axis=1, keepdims = True, interpolation = 'nearest') # can't use 'method' because my python is outdated\n",
    "upperCI = pd.DataFrame(np.squeeze(upperCI), columns=['upper']).reset_index().rename(columns={'index':classification})\n",
    "lowerCI = pd.DataFrame(np.squeeze(lowerCI), columns=['lower']).reset_index().rename(columns={'index':classification})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Figure 4B & C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 95-CI over the frequencies, with optional individual dots for each game\n",
    "gameNormFreqs = D4.groupby(['gameID'])[['1norm','2norm','3norm','4norm']].mean()\n",
    "mean = gameNormFreqs.mean()\n",
    "yerr = D4.groupby(['gameID'])[['1norm','2norm','3norm','4norm']].mean().apply(getCI95)\n",
    "\n",
    "f , (ax1,ax2) = plt.subplots(1,2,figsize=(8,3.5),sharey=True,\n",
    "                             gridspec_kw={'width_ratios': [1.2, 4]})\n",
    "\n",
    "barw = .8\n",
    "mean.plot.bar(ax=ax1,\n",
    "              yerr=yerr,\n",
    "              xlabel=\"Symbol\",\n",
    "              ylabel='Normed Frequency',rot=0,\n",
    "              width=barw,\n",
    "              capsize=8,\n",
    "              edgecolor='k',\n",
    "              fill=None,\n",
    "              error_kw=dict(ecolor='k',lw=lw, capsize=cs, capthick=lw))\n",
    "\n",
    "for game in gameNormFreqs.index:\n",
    "    offsets = (np.random.rand(4)-.5) / 4\n",
    "    curMeansX = [0,1,2,3] + offsets\n",
    "    curMeansY = gameNormFreqs.loc[game].T.to_frame()[game]\n",
    "ax1.set_xticklabels(['1','2','3','4']) # we will replace these with images that are more intuitive\n",
    "\n",
    "\n",
    "temp = pd.DataFrame(simpsons).reset_index()\n",
    "sns.lineplot(data=upperCI, x=classification, y='upper',color=c3,ax=ax2)\n",
    "sns.lineplot(data=lowerCI, x=classification, y='lower',color=c3,ax=ax2)\n",
    "ax2.fill_between(upperCI[classification], lowerCI['lower'], upperCI['upper'], facecolor=c3, alpha=.5)\n",
    "sns.pointplot(data=temp, x=classification, y='Simpson',color='k',markers='o',ax=ax2)\n",
    "\n",
    "plt.ylim([0,1])\n",
    "plt.xlabel(\"Cardinality\")\n",
    "ax1.set_xticklabels(['1','2','3','4'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axes2 = ax2.twinx()\n",
    "axes2.set_ylabel(\"Symbol Diversity\",rotation=270)   # \"Simpson's Diversity Index\"\n",
    "axes2.set_yticks([])\n",
    "axes2.yaxis.set_label_coords(1.08 , .5)\n",
    "\n",
    "\n",
    "ax1.set_yticks([])\n",
    "ax1.set_yticklabels([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_yticklabels([])\n",
    "\n",
    "\n",
    "ax1.set_yticks([0,.5,1])\n",
    "ax1.set_yticklabels(['0','.5','1'])\n",
    "ax1.yaxis.tick_right()\n",
    "\n",
    "\n",
    "ax2.set_xticks([3,7,11,15])\n",
    "ax2.set_xticklabels(['4','8','12','16'])\n",
    "ax2.set_xlim(-.2,15.2)\n",
    "\n",
    "\n",
    "ax1.yaxis.set_minor_locator(plt.NullLocator())\n",
    "\n",
    "\n",
    "plt.tight_layout(w_pad=.2)\n",
    "f.savefig('../results/plots/Fig_4BC.pdf')\n",
    "# f.savefig('../results/plots/Fig_4BC.png')\n",
    "# f.savefig('../results/plots/Fig_4BC.svg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
