{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "import pymongo as pm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import base64\n",
    "import PIL\n",
    "\n",
    "from bezier import curve\n",
    "from svg.path import Path, Line, Arc, CubicBezier, QuadraticBezier, Close, parse_path\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import importlib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "# so dataframes don't get cut off in display:\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "gallery_dir = os.path.abspath(os.path.join(proj_dir,'gallery'))\n",
    "\n",
    "## add helpers to python path\n",
    "if os.path.join(proj_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'utils'))   \n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [results_dir,plot_dir,csv_dir,sketch_dir,gallery_dir]]\n",
    "\n",
    "## add utils to python path\n",
    "import sys\n",
    "if os.path.join(proj_dir,'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir,'utils'))\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### establish connection to mongo\n",
    "first thing you need to do is to establish an ssh tunnel (aka remote port forwarding) to the server, so that requests to the mongodb can be made \"as if\" the mongodb server is running on your local computer. Run this from the command line before you begin data analysis if you plan to fetch data from mongo:\n",
    "\n",
    "ssh -fNL 27020:127.0.0.1:27017 USER@cogtoolslab.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ssh -fNL 27020:127.0.0.1:27017 sholt@cogtoolslab.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set vars \n",
    "auth = pd.read_csv(os.path.join(analysis_dir,'auth.txt'), header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'cogtoolslab.org'\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "import pymongo as pm\n",
    "import socket\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1:27017')\n",
    "db = conn['iterated_number']\n",
    "coll = db['num8_shape4']\n",
    "\n",
    "# which iteration name should we use?\n",
    "iterationName = 'sandbox3' #increment when needed\n",
    "# this has previously been run1, but switched to sandbox 3 for testing the url recording function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## here is what one of these records looks like\n",
    "coll.find_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trials\n",
    "k = coll.find({'iterationName':iterationName, 'eventType':'clickedObj'})\n",
    "K = pd.DataFrame(k)\n",
    "\n",
    "## strokes\n",
    "t = coll.find({'iterationName':iterationName, 'eventType':'stroke'})\n",
    "T = pd.DataFrame(t)\n",
    "\n",
    "## get list of valid game IDs (i.e, subject number)\n",
    "from collections import Counter\n",
    "game_dict = Counter(K['gameid']) ## get dictionary mapping gameIDs to number of sketches \n",
    "complete_gameids = [k for (k,v) in game_dict.items() if v==32] ## get gameids that contributed exactly the right number of sketches\n",
    "\n",
    "## subset stroke/sketch dataframes by being complete AND also exclude practice\n",
    "subset = True\n",
    "if (subset and T['gameid'].nunique()!=len(complete_gameids)):\n",
    "    T = T[(T['gameid'].isin(complete_gameids))].reset_index(drop=True)\n",
    "    K = K[(K['gameid'].isin(complete_gameids))].reset_index(drop=True)\n",
    "    \n",
    "print('We have {} unique stroke records in all {} of our complete games.'.format(T.shape[0],len(complete_gameids)))\n",
    "print('We have {} unique sketch records in all {} of our complete games.'.format(K.shape[0],len(complete_gameids)))\n",
    "\n",
    "## save out to csv\n",
    "T.to_csv(os.path.join(csv_dir,'photodraw_stroke_data.csv'),index=False)\n",
    "K.to_csv(os.path.join(csv_dir,'photodraw_sketch_data.csv'),index=False)\n",
    "\n",
    "## generate group dataframe and save out to file\n",
    "importlib.reload(utils)\n",
    "D = utils.generate_dataframe(coll, complete_gameids, iterationName, csv_dir)\n",
    "\n",
    "# Turning things that can be numeric into numeric things\n",
    "D = D.astype({'trialNum': 'float',\n",
    "              'cardinality': 'float',\n",
    "              'drawDuration': 'float',\n",
    "              'outcome': 'float',\n",
    "              'numStrokes': 'float',\n",
    "              'meanPixelIntensity': 'float',\n",
    "              'numCurvesPerSketch': 'float',\n",
    "              'numCurvesPerStroke': 'float',\n",
    "              'D1_Car': 'float',\n",
    "              'D2_Car': 'float',\n",
    "              'D3_Car': 'float'})\n",
    "\n",
    "def GetArcLenData(df):\n",
    "    \"\"\"\n",
    "    This requires the dataframe to have a ['svgString'] column to analyse.\n",
    "    It returns the same dataframe, but with an extra column of 'stroke_len_means'.\n",
    "    Currently just taking the total arc length of each stroke, and averaging them per sketch.\n",
    "    \n",
    "    If not already, import Path, Arc, CubicBezier, and parse_path from svg.path\n",
    "    Used this: https://pypi.org/project/svg.path/\n",
    "    \"\"\"\n",
    "    stroke_len_means = []\n",
    "    for row_num in range(len(df['svgString'])):\n",
    "        stroke_lengths = []\n",
    "        for stroke_num in range(len(df['svgString'][row_num])):\n",
    "            stroke_length = 0\n",
    "            for curve in parse_path(D['svgString'][row_num][stroke_num]):\n",
    "                stroke_length += curve.length(error=1e-5)\n",
    "            stroke_lengths.append(stroke_length)\n",
    "        stroke_len_means.append(np.mean(stroke_lengths))\n",
    "    new_df = df\n",
    "    new_df['stroke_len_means'] = stroke_len_means\n",
    "    return new_df\n",
    "\n",
    "D = GetArcLenData(D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## monitor how far along games-in-progress are\n",
    "all_games = K['gameid'].unique()\n",
    "num_games = len(all_games)\n",
    "print('There are a total of {} unique gameids in mongo.'.format(num_games))\n",
    "\n",
    "print('\\n')\n",
    "print('These are the games and how many trials have been completed so far:')\n",
    "for name, group in K.groupby('gameid'):\n",
    "    print('gameid: {} | number of trials : {}'.format(name, group.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: hash 'workerId' so that we do not save actual workerIDs to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### render out all the sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "utils.render_images(K,data = 'pngString',\n",
    "                    metadata = ['gameid','intendedName','trialNum'],\n",
    "                    out_dir = sketch_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make sketch gallery (for complete games only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "## actually render sketch gallery for each complete game\n",
    "utils.render_sketch_gallery(complete_gameids, \n",
    "                     sketch_dir = sketch_dir,\n",
    "                     gallery_dir = gallery_dir,\n",
    "                     num_trials = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional derived measures we might want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just trials where all distractors were of different animal category than the target\n",
    "D_animal = D.loc[(D['category'] != D['D1_Cat']) & (D['category'] != D['D2_Cat']) & (D['category'] != D['D3_Cat'])]\n",
    "D_animal[['trialNum','category','cardinality','D1_Cat','D1_Car','D2_Cat','D2_Car','D3_Cat','D3_Car']]\n",
    "\n",
    "\n",
    "# Which quarter of the experiment the trial happened in\n",
    "D['quarter'] = np.ceil(D['trialNum']/8)\n",
    "D = D.astype({'quarter': 'float'})\n",
    "\n",
    "# subtract the first quarter from the fourth quarter to get delta of different measures\n",
    "D_1st = D.loc[D['quarter'] == 1.0]\n",
    "D_2nd = D.loc[D['quarter'] == 2.0]\n",
    "D_3rd = D.loc[D['quarter'] == 3.0]\n",
    "D_4th = D.loc[D['quarter'] == 4.0]\n",
    "\n",
    "\n",
    "\n",
    "# to get differences between 1st and 3rd\n",
    "D1_sorted = D_1st.sort_values('cardinality')[['cardinality','meanPixelIntensity']].to_numpy()\n",
    "D4_sorted = D_4th.sort_values('cardinality')[['cardinality','meanPixelIntensity']].to_numpy()\n",
    "\n",
    "D_diff = pd.DataFrame({'cardinality': D1_sorted[:,0],\n",
    "                       'pixelIntensityDiff': D1_sorted[:,1] - D4_sorted[:,1]})\n",
    "\n",
    "\n",
    "# General purpose function for plotting measurements separately by quarter of the experiment\n",
    "def PlotByQuarter(title,xvar='cardinality',yvar='numStrokes',ylabel='Strokes per Sketch'):\n",
    "    if xvar=='cardinality':\n",
    "        xlabel = 'Cardinality'\n",
    "    elif xvar=='category':\n",
    "        xlabel = 'Animal'\n",
    "    plt.figure(title)\n",
    "    plt.title(title)\n",
    "    sns.pointplot(data=D_1st, x=xvar, y=yvar,color='#000000',markers='.')\n",
    "    sns.pointplot(data=D_2nd, x=xvar, y=yvar,color='#bb3f3f',markers='.')\n",
    "    sns.pointplot(data=D_3rd, x=xvar, y=yvar,color='#edda07',markers='.')\n",
    "    sns.pointplot(data=D_4th, x=xvar, y=yvar,color='#6a0dad',markers='.')\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    black_patch = mpatches.Patch(color='#000000', label='1st round')\n",
    "    red_patch = mpatches.Patch(color='#bb3f3f', label='2nd round')\n",
    "    yellow_patch = mpatches.Patch(color='#edda07', label='3rd round')\n",
    "    purple_patch = mpatches.Patch(color='#6a0dad', label='4th round')\n",
    "    plt.legend(handles=[black_patch, red_patch, yellow_patch, purple_patch])\n",
    "\n",
    "PlotByQuarter(\"Ink by Cardinality\",yvar='meanPixelIntensity',ylabel=\"Mean Pixel Intensity\")\n",
    "PlotByQuarter(\"Strokes per Sketch\",yvar='numStrokes',ylabel=\"Strokes per Sketch\")\n",
    "PlotByQuarter(\"Curves per Stroke\",yvar='numCurvesPerStroke',ylabel=\"Curves per Stroke\")\n",
    "\n",
    "PlotByQuarter(\"Curves per Stroke (Animal)\",xvar='category',yvar='numCurvesPerStroke',ylabel=\"Curves per Stroke\")\n",
    "PlotByQuarter(\"Strokes per Sketch (Animal)\",xvar='category',yvar='numStrokes',ylabel=\"Strokes per Sketch\")\n",
    "\n",
    "PlotByQuarter(\"Mean Stroke Length by Cardinality\",yvar='stroke_len_means',ylabel=\"Mean Stroke Length\")\n",
    "PlotByQuarter(\"Sketch Time by Cardinality\",yvar='drawDuration',ylabel=\"Sketch Time\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### analyze performance (accuracy and RT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_table = D.groupby('gameID')['outcome'].mean().reset_index()\n",
    "acc_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D['drawDuration'] = pd.to_numeric(D['drawDuration'])\n",
    "acc_table = D.groupby('gameID')['drawDuration'].mean().reset_index()\n",
    "acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for some reason, .mean() doesn't work on these. But .sum() and .count() do, so gonna use that\n",
    "x = D.groupby(['cardinality'])[['cardinality','numCurvesPerStroke']].sum()\n",
    "y = D.groupby(['cardinality'])[['cardinality','numCurvesPerStroke']].count()\n",
    "\n",
    "print(x/y)\n",
    "#sns.pointplot(data=D, x='trialNum', y='numCurvesPerStroke')\n",
    "sns.pointplot(data=D, x='trialNum', y='numCurvesPerStroke')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What statistics do we want to look at?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measures of iconicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complexity (number of curves) and ink (pixel intensity) per cardinality and between animals\n",
    "\n",
    "plt.figure()\n",
    "sns.barplot(data=D, x='cardinality', y='numStrokes')\n",
    "plt.figure()\n",
    "sns.barplot(data=D, x='cardinality', y='numCurvesPerSketch')\n",
    "plt.figure()\n",
    "sns.barplot(data=D, x='cardinality', y='meanPixelIntensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.barplot(data=D, x='category', y='numStrokes')\n",
    "plt.figure()\n",
    "sns.barplot(data=D, x='category', y='numCurvesPerSketch')\n",
    "plt.figure()\n",
    "sns.barplot(data=D, x='category', y='meanPixelIntensity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear regression....\n",
    "\n",
    "\n",
    "#stats.linregress(D.groupby('cardinality')['drawDuration'])\n",
    "D.groupby(['cardinality'])[['quarter','drawDuration']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
