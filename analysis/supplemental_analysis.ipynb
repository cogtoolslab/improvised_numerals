{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supplemental Analysis S1\n",
    "Prior to running this notebook, navigate to the `/utils/` folder and run the following command to get feature vectors that this analysis looks at:\n",
    "\n",
    "`! python extract_features.py --data='../results/bare_sketches' --layer_ind=5 --data_type='sketch' --spatial_avg=True --channel_norm=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division\n",
    "import os\n",
    "import urllib\n",
    "from io import BytesIO     # for handling byte strings\n",
    "from io import StringIO    # for handling unicode strings\n",
    "import pymongo as pm\n",
    "import math\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "from sklearn.metrics import *\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from joblib import dump, load\n",
    "from PIL import Image\n",
    "import base64\n",
    "import sys\n",
    "import matplotlib\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['pdf.fonttype'] = 42\n",
    "# mpl.rcParams['pdf.fonttype'] = 42\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.lines as mlines\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')\n",
    "from sklearn import linear_model, datasets, neighbors, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from IPython.display import clear_output\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "analysis_dir = os.getcwd()\n",
    "feature_dir = os.path.abspath(os.path.join(proj_dir,'results/csv/features'))\n",
    "classif_dir = os.path.abspath(os.path.join(proj_dir,'results/csv/classifier'))\n",
    "plot_dir =     os.path.join(proj_dir,'results/plots')\n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [feature_dir,classif_dir,plot_dir]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get only the features from one layer of the NN, FC6\n",
    "FEAT = np.load(os.path.join(feature_dir, \"FEATURES_FC6_sketch_channel-norm.npy\"))\n",
    "num_feats = np.shape(FEAT)[1] # the first dimension is number of sketches, second is number of features     \n",
    "FEAT = pd.DataFrame(FEAT)\n",
    "feat_cols = [str(i) for i in np.arange(num_feats)]\n",
    "FEAT.columns = feat_cols\n",
    "# FEAT.columns = FEAT.columns.astype(int)\n",
    "\n",
    "META = pd.read_csv(os.path.join(feature_dir,'METADATA_sketch.csv'))\n",
    "assert META.shape[0]==FEAT.shape[0]\n",
    "META['game_id'] = META.sketch_id.str.split('_').str[0]\n",
    "META['animal'] = META.sketch_id.str.split('_').str[1]\n",
    "META['cardinality'] = META.sketch_id.str.split('_').str[2]\n",
    "META['trial_num'] = META.sketch_id.str.split('_').str[3]\n",
    "META['condition'] = META.sketch_id.str.split('_').str[4]\n",
    "META.drop(columns=['feature_ind'],inplace=True)\n",
    "\n",
    "D = pd.concat([META,FEAT],axis=1)\n",
    "D = D.astype({'trial_num': 'float'})\n",
    "D['block'] = np.ceil(D['trial_num']/8)\n",
    "D = D.astype({'block': 'float'})\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splits(df, \n",
    "               folds=5, \n",
    "               random_seed=132,\n",
    "               replace=False,\n",
    "               group='animal',\n",
    "               identifier='sketch_id'):\n",
    "    \n",
    "    num_obs_per_group = int(df.groupby(group).size().mean())\n",
    "    size = int(num_obs_per_group / folds)## how many obs do include in each split    \n",
    "    replace = False  # without replacement\n",
    "    ## create splits\n",
    "    splits = []\n",
    "    counter = 0\n",
    "    while counter < folds:\n",
    "        fn = lambda obj: obj.loc[np.random.RandomState(random_seed).choice(obj.index, size, replace),:]    \n",
    "        current_split = df.groupby(group, as_index=False).apply(fn)\n",
    "        used_ids = current_split.sketch_id.unique()\n",
    "        \n",
    "        df = df[~df.sketch_id.isin(used_ids)]\n",
    "        \n",
    "        ## sanity check, there is no overlap in image_id\n",
    "        assert len(np.intersect1d(current_split[identifier],df[identifier]))==0\n",
    "        splits.append(current_split.reset_index(drop=True))\n",
    "        counter += 1\n",
    "        \n",
    "    splits[-1] = splits[-1].append(df)\n",
    "    \n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_scoring(clfCond,gameCond):\n",
    "    DF = D[D['condition'] == gameCond] # number or shape\n",
    "    splits = get_splits(DF,group=clfCond) # cardinality or animal\n",
    "    \n",
    "    acc = []\n",
    "    clf_score_name = 'clfScore_' + clfCond\n",
    "    merging_df = pd.DataFrame(columns = ['sketch_id',clf_score_name])\n",
    "    \n",
    "    for ind,df in enumerate(splits):\n",
    "        print(\"Working on {} of {}\".format(ind+1,len(splits)))\n",
    "        training_dfs = splits[:ind] + splits[ind+1:]\n",
    "        trainset = pd.concat(training_dfs)\n",
    "        testset = df\n",
    "\n",
    "        Xtrain, Xtest = np.array(trainset[feat_cols]), np.array(testset[feat_cols])\n",
    "        ytrain, ytest = trainset[clfCond].values, testset[clfCond].values\n",
    "        \n",
    "        clf = linear_model.LogisticRegression(penalty='l2',\n",
    "                                          C=1e-3,\n",
    "                                          random_state=0,\n",
    "                                          solver='lbfgs',\n",
    "                                          multi_class='multinomial',\n",
    "                                          max_iter=1500)\n",
    "        clf.fit(Xtrain,ytrain)\n",
    "        score = clf.score(Xtest, ytest)\n",
    "        acc.append(score)\n",
    "        predictions = clf.predict(Xtest)\n",
    "        split_confmat = confusion_matrix(ytest, predictions)\n",
    "        \n",
    "        \n",
    "        df[clf_score_name] = predictions\n",
    "        addendum_for_merging = df[['sketch_id',clf_score_name]]\n",
    "        merging_df = merging_df.append(addendum_for_merging)\n",
    "        \n",
    "        \n",
    "        confmat = split_confmat if ind == 0 else split_confmat + confmat\n",
    "    \n",
    "    return [acc,confmat,merging_df]\n",
    "\n",
    "# A=animal,C=cardinality ; S=shape,N=number\n",
    "print(\"Working on animal-animal condition...\")\n",
    "ASacc,ASconf,ASdf = clf_scoring('animal','shape')\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"Working on animal-number condition...\")\n",
    "ANacc,ANconf,ANdf = clf_scoring('animal','number')\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"Working on number-animal condition...\")\n",
    "CSacc,CSconf,CSdf = clf_scoring('cardinality','shape')\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(\"Working on number-number condition...\")\n",
    "CNacc,CNconf,CNdf = clf_scoring('cardinality','number')\n",
    "clear_output(wait=True)\n",
    "\n",
    "# put together the full dataframe\n",
    "mergeDFanimal = ASdf.append(ANdf)\n",
    "mergeDFcardinality = CSdf.append(CNdf)\n",
    "D = D.merge(mergeDFanimal,on=\"sketch_id\")\n",
    "D = D.merge(mergeDFcardinality,on=\"sketch_id\")\n",
    "\n",
    "saveD = D.copy()\n",
    "saveD.drop(D.columns[6:4102], axis=1, inplace=True) # these just happen to be the feature columns, which we don't need\n",
    "saveD.to_csv(os.path.join(classif_dir,\"clfD.csv\"))\n",
    "\n",
    "# save out the confmats to the directory so we can import them into our recog analysis\n",
    "np.save(os.path.join(classif_dir,\"AA_CLFconfmat.npy\"), ASconf)\n",
    "np.save(os.path.join(classif_dir,\"CA_CLFconfmat.npy\"), ANconf) #number production, animal recog\n",
    "np.save(os.path.join(classif_dir,\"AC_CLFconfmat.npy\"), CSconf) #shape production, cardinality recog\n",
    "np.save(os.path.join(classif_dir,\"CC_CLFconfmat.npy\"), CNconf)\n",
    "\n",
    "np.save(os.path.join(classif_dir,\"AA_CLFacc.npy\"), ASacc)\n",
    "np.save(os.path.join(classif_dir,\"CA_CLFacc.npy\"), ANacc) #number production, animal recog\n",
    "np.save(os.path.join(classif_dir,\"AC_CLFacc.npy\"), CSacc) #shape production, cardinality recog\n",
    "np.save(os.path.join(classif_dir,\"CC_CLFacc.npy\"), CNacc)\n",
    "\n",
    "\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cf95(arr, z=1.96):\n",
    "    mean = np.mean(arr)\n",
    "    std = np.std(arr)\n",
    "    answer = z * std / np.sqrt(np.size(arr))\n",
    "    return answer\n",
    "\n",
    "fig , (ax1,ax2) = plt.subplots(1,2 , sharey=True, figsize = (8,4))\n",
    "\n",
    "ax1.set_ylim(0,1)\n",
    "\n",
    "\n",
    "# this subplot is for predicting shape\n",
    "ax1.bar([\"CA\",\"AA\"],\n",
    "        [np.mean(ANacc), # predicting animals based on numbers\n",
    "         np.mean(ASacc)], # predicting animals based on animals\n",
    "        color = ['#7DCCF4','#787878'],\n",
    "        yerr = [cf95(ANacc),\n",
    "                cf95(ASacc)], error_kw={'linewidth':3,'capsize':3})\n",
    "\n",
    "# this subplot is for predicting number\n",
    "ax2.bar([\"CC\",\"AC\"],\n",
    "        [np.mean(CNacc),\n",
    "         np.mean(CSacc)],\n",
    "        color = ['#7DCCF4','#787878'],\n",
    "        yerr = [cf95(CNacc),\n",
    "                cf95(CSacc)], error_kw={'linewidth':3,'capsize':3})\n",
    "\n",
    "colors = {'Number Sketches':'#7DCCF4', 'Shape Sketches':'#787878'}         \n",
    "labels = list(colors.keys())\n",
    "handles = [plt.Rectangle((0,0),1,1, color=colors[label]) for label in labels]\n",
    "ax2.legend(handles, labels)\n",
    "\n",
    "\n",
    "l1=ax1.axhline(0.25,color='black',ls='--')\n",
    "l1.set_label('l1')\n",
    "\n",
    "l2=ax2.axhline(0.125,color='black',ls='--')\n",
    "l2.set_label('l2')\n",
    "\n",
    "ax1.set_xlabel(\"'Guessing' Shape\",color='k')\n",
    "ax1.set_xticklabels([])\n",
    "ax1.set_yticks([])\n",
    "\n",
    "ax1.set_yticks([0,1])\n",
    "ax1.set_yticklabels(['0','1'])\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax2.set_xlabel(\"'Guessing' Number\",color='k')\n",
    "ax2.set_xticklabels([])\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.suptitle(\"VGG-19 Classifications\",fontsize=24,x=.56,y=1.02)\n",
    "\n",
    "\n",
    "fig.savefig('../results/plots/Fig_S1.pdf', bbox_inches=\"tight\")\n",
    "# fig.savefig('../results/plots/Fig_S1.png', bbox_inches=\"tight\")\n",
    "# fig.savefig('../results/plots/Fig_S1.svg', bbox_inches=\"tight\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Congruent Classifications\")\n",
    "print(\"Number Games & Number Ratings    {}%, CI: [{}, {}]\".format(np.round(np.mean(CNacc)*100,1),\n",
    "                                                              np.round((np.mean(CNacc) + cf95(CNacc))*100,1),\n",
    "                                                              np.round((np.mean(CNacc) - cf95(CNacc))*100,1)))\n",
    "\n",
    "print(\"Animal Games & Animal Ratings    {}%, CI: [{}, {}]\".format(np.round(np.mean(ASacc)*100,1),\n",
    "                                                              np.round((np.mean(ASacc) + cf95(ASacc))*100,1),\n",
    "                                                              np.round((np.mean(ASacc) - cf95(ASacc))*100,1)),end='\\n\\n')\n",
    "\n",
    "print(\"Incongruent Classifications\")\n",
    "print(\"Animal Games & Number Ratings    {}%, CI: [{}, {}]\".format(np.round(np.mean(ANacc)*100,1),\n",
    "                                                              np.round((np.mean(ANacc) + cf95(ANacc))*100,1),\n",
    "                                                              np.round((np.mean(ANacc) - cf95(ANacc))*100,1)))\n",
    "\n",
    "print(\"Number Games & Animal Ratings    {}%, CI: [{}, {}]\".format(np.round(np.mean(CSacc)*100,1),\n",
    "                                                              np.round((np.mean(CSacc) + cf95(CSacc))*100,1),\n",
    "                                                              np.round((np.mean(CSacc) - cf95(CSacc))*100,1)),end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
